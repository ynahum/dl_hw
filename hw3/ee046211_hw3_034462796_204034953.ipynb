{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzV9wsJ5pGhf"
      },
      "source": [
        "# <img src=\"https://img.icons8.com/bubbles/50/000000/mind-map.png\" style=\"height:50px;display:inline\"> EE 046211 - Technion - Deep Learning\n",
        "---\n",
        "\n",
        "## HW3 - Sequential Tasks and Training Methods\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bq2c8X93pGhh"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/clouds/96/000000/keyboard.png\" style=\"height:50px;display:inline\"> Keyboard Shortcuts\n",
        "---\n",
        "* Run current cell: **Ctrl + Enter**\n",
        "* Run current cell and move to the next: **Shift + Enter**\n",
        "* Show lines in a code cell: **Esc + L**\n",
        "* View function documentation: **Shift + Tab** inside the parenthesis or `help(name_of_module)`\n",
        "* New cell below: **Esc + B**\n",
        "* Delete cell: **Esc + D, D** (two D's)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZZybn3NpGhh"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/bubbles/50/000000/information.png\" style=\"height:50px;display:inline\"> Students Information\n",
        "---\n",
        "* Fill in\n",
        "\n",
        "|Name         |Campus Email                     | ID       |\n",
        "|-------------|---------------------------------|----------|\n",
        "|Lior Friedman| liorf@campus.technion.ac.il     | 204034953|\n",
        "|Yair Nahum   | nahum.yair@campus.technion.ac.il| 034462796|\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDK5zqhdpGhi"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/bubbles/50/000000/upload-to-cloud.png\" style=\"height:50px;display:inline\"> Submission Guidelines\n",
        "---\n",
        "* Maximal garde: 100.\n",
        "* Submission only in **pairs**. \n",
        "    * Please make sure you have registered your group in Moodle (there is a group creation component on the Moodle where you need to create your group and assign members).\n",
        "* **No handwritten submissions.** You can choose whether to answer in a Markdown cell in this notebook or attach a PDF with your answers.\n",
        "* <a style='color:red'> SAVE THE NOTEBOOKS WITH THE OUTPUT, CODE CELLS THAT WERE NOT RUN WILL NOT GET ANY POINTS! </a>\n",
        "* What you have to submit:\n",
        "    * If you have answered the questions in the notebook, you should submit this file only, with the name: `ee046211_hw3_id1_id2.ipynb`.\n",
        "    * If you answered the questionss in a different file you should submit a `.zip` file with the name `ee046211_hw3_id1_id2.zip` with content:\n",
        "        * `ee046211_hw3_id1_id2.ipynb` - the code tasks\n",
        "        * `ee046211_hw3_id1_id2.pdf` - answers to questions.\n",
        "    * No other file-types (`.py`, `.docx`...) will be accepted.\n",
        "* Submission on the course website (Moodle).\n",
        "* **Latex in Colab** - in some cases, Latex equations may no be rendered. To avoid this, make sure to not use *bullets* in your answers (\"* some text here with Latex equations\" -> \"some text here with Latex equations\")."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmSj_UufpGhi"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/dusk/64/000000/online.png\" style=\"height:50px;display:inline\"> Working Online and Locally\n",
        "---\n",
        "* You can choose your working environment:\n",
        "    1. `Jupyter Notebook`, **locally** with <a href=\"https://www.anaconda.com/distribution/\">Anaconda</a> or **online** on <a href=\"https://colab.research.google.com/\">Google Colab</a>\n",
        "        * Colab also supports running code on GPU, so if you don't have one, Colab is the way to go. To enable GPU on Colab, in the menu: `Runtime`$\\rightarrow$ `Change Runtime Type` $\\rightarrow$`GPU`.\n",
        "    2. Python IDE such as <a href=\"https://www.jetbrains.com/pycharm/\">PyCharm</a> or <a href=\"https://code.visualstudio.com/\">Visual Studio Code</a>.\n",
        "        * Both allow editing and running Jupyter Notebooks.\n",
        "\n",
        "* Please refer to `Setting Up the Working Environment.pdf` on the Moodle or our GitHub (https://github.com/taldatech/ee046211-deep-learning) to help you get everything installed.\n",
        "* If you need any technical assistance, please go to our Piazza forum (`hw3` folder) and describe your problem (preferably with images)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlp1Fp4ppGhj"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/bubbles/50/000000/checklist.png\" style=\"height:50px;display:inline\"> Agenda\n",
        "---\n",
        "\n",
        "* [Part 1 - Theory](#-Part-1---Theory)\n",
        "    * [Q1 - Deep NLP Case Study](#-Question-1--Deep-NLP-Case-Study)\n",
        "    * [Q2 -Layer Normalization](#-Question-2--Layer-Normalization)\n",
        "    * [Q3 - Batch Normalization](#-Question-3--Batch-Normalization)\n",
        "* [Part 2 - Code Assignments - Sequence-to-Sequence with Transformers](#-Part-2---Code-Assignments)\n",
        "    * [Task 1 - Task 1 - Loading and Observing the Data](#-Task-1----Loading-and-Observing-the-Data)\n",
        "    * [Task 2 - Preparing the Data - Separating to Inputs and Targets](#-Task-2----Preparing-the--Data---Separating-to-Inputs-and-Targets)\n",
        "    * [Task 3 - Define Hyperparameters and Initialize the Model](#-Task-3----Define-Hyperparameters-and-Initialize-the-Model)\n",
        "    * [Task 4 - Train and Evaluate the Language Model](#-Task-4----Train-and-Evaluate-the-Language-Model)\n",
        "    * [Task 5 - Generate Sentences](#-Task-5----Generate-Sentences)\n",
        "* [Credits](#-Credits)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKtSiQX_pGhj"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/cute-clipart/64/000000/ball-point-pen.png\" style=\"height:50px;display:inline\"> Part 1 - Theory\n",
        "---\n",
        "* You can choose whether to answser these straight in the notebook (Markdown + Latex) or use another editor (Word, LyX, Latex, Overleaf...) and submit an additional PDF file, **but no handwritten submissions**.\n",
        "* You can attach additional figures (drawings, graphs,...) in a separate PDF file, just make sure to refer to them in your answers.\n",
        "\n",
        "* $\\large\\LaTeX$ <a href=\"https://kapeli.com/cheat_sheets/LaTeX_Math_Symbols.docset/Contents/Resources/Documents/index\">Cheat-Sheet</a> (to write equations)\n",
        "    * <a href=\"http://tug.ctan.org/info/latex-refsheet/LaTeX_RefSheet.pdf\">Another Cheat-Sheet</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsqSFZG1pGhj"
      },
      "source": [
        "## <img src=\"https://img.icons8.com/clouds/100/000000/question-mark.png\" style=\"height:50px;display:inline\"> Question 1 -Deep NLP Case Study\n",
        "---\n",
        "* You are consulting for a healthcare company. They provide you with clinical notes of the first encounter that each patient had with their doctor regarding a particular medical episode.\n",
        "* There are a total of 12 million patients and clinical notes. At the time that each clinical note was written, the underlying illnesses associated with the medical episode were unknown to the doctor. \n",
        "* The company provides you with the true set of illnesses associated with each medical episode and asks you to build a model that can infer these underlying illnesses using only the current clinical note and all previous clinical notes belonging to the patient.\n",
        "* The set of notes provided to you span 10 years; each patient therefore can have multiple clinical notes (medical episodes) in that period.\n",
        "* You also have a vector representation of each patient note (note-vector) which was built using a summation of the word vectors of the note.\n",
        "\n",
        "\n",
        "1. You assume that a patient’s past medical history is informative of their current illness. As such, you apply a recurrent neural network to predict the current illness based on the patient’s current and previous note-vectors. Explain why a recurrent neural network would yield better results than a feed-forward network in which your input is the summation of past and current note-vectors?\n",
        "\n",
        "2. A patient may have any number of illnesses from a list of 70,000 known medical illnesses. The output of your recurrent neural network will therefore be a vector with 70,000 elements. Each element in this output vector represents the probability that the patient has the illness that maps to that particular element. Illnesses are not mutually exclusive i.e. having one illness does not preclude you from having any other illnesses. Given this insight, is it better to have a sigmoid non-linearity or a softmax non-linearity as your output unit? Why?\n",
        "\n",
        "3. You try to figure out a better way to reduce the training and testing time of your model. You perform a run time analysis and observe that the computational bottleneck is in your output unit: the number of target illnesses is too high. Each illness in the list of 70,000 illnesses belongs to one of 300 classes (e.g. a migraine belongs to the neurological disorder class). He shares with you a dictionary which maps each illness to its corresponding class. How can you use this information to reduce the **time** complexity of your model?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHrAd9Qcpt6Z"
      },
      "source": [
        "## <img src=\"https://img.icons8.com/fluency/48/000000/exclamation-mark.png\" style=\"height:50px;display:inline\">  Answer 1 - Deep NLP Case Study\n",
        "---\n",
        "\n",
        "1. The RNN structure allows us to preserve and learn the time relations between tokens/events (as in RL actions and rewards) while summation lose the chronological order between them. In RNNs usually the recent events have more significance compared to old events (BTW, in time sequences tasks like NLP, there are models that even assume Markovian assumption on next word/event probablilty).  \n",
        "2. It is better to use a sigmoid as the probablility to have some illness is independent in other illnesses probabilities. If we use softmax, one probability for some illness influences the other illnesses probability as we normailize all such that the sum of all probabilities equal 1.  \n",
        "   This is a multi-label classification (we can have several outputs independent on other outputs).  \n",
        "3. We use the hidden layer to predict the 300 classes (As we have for each time step the illnesses we can create labels for the classes, compute a loss and train the classes predictor) we do that with some $W_{300xd_h}$ and softmax over the 300 neurons.  \n",
        "   Then, we take the top N (for example=10) classes with the highest probabilities and get the opposite illnesses that might have caused these (the inverse mapping of each class).  \n",
        "   From that we deduce the possible illnesses the patient might have and caculate the outputs of the RNN only on them.  \n",
        "   For example, we get from the 300 classes the highest 10 classes. These classes give about $10 \\times (70,000 / 300 ) = 2330 $ possible illnesses (assuming uniform distribution). On these illnesses we calculate the prediction and backprop only on them in training time.  \n",
        "   Every episode of patient can give different illnesses to backprop on into the RNN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JChYvPxkpt6c"
      },
      "source": [
        "## <img src=\"https://img.icons8.com/clouds/100/000000/question-mark.png\" style=\"height:50px;display:inline\"> Question 2 -Layer Normalization\n",
        "---\n",
        "\n",
        "1. When does Group Normalization is equivalent to Instance Normalization?\n",
        "2. When does Group Normalization is equivalent to Layer Normalization?\n",
        "3. For the following batch of $N=3$ 2D images with $C=3$ channels each, what is the output of:\n",
        "    * Batch Normalization\n",
        "    * Layer Normalization\n",
        "    * Instance Normalization\n",
        "\n",
        "\n",
        "* Use only the *mean* for the calculation, no need for the std (assume there are no learnable parameters).\n",
        "    \n",
        "$$ n=1: \\begin{bmatrix} 0 & 1 \\\\ 1 & 0 \\end{bmatrix}, \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}, \\begin{bmatrix} 1 & 1 \\\\ 1 & 1 \\end{bmatrix} $$\n",
        "\n",
        "$$ n=2: \\begin{bmatrix} 0.5 & 0.5 \\\\ 0.5 & 0.5 \\end{bmatrix}, \\begin{bmatrix} 0.5 & 0 \\\\ 0.5 & 0 \\end{bmatrix}, \\begin{bmatrix} 0 & 0.5 \\\\ 0 & 0.5 \\end{bmatrix} $$\n",
        "\n",
        "$$ n=3: \\begin{bmatrix} 1 & 1 \\\\ 1 & 0.5 \\end{bmatrix}, \\begin{bmatrix} 0.5 & 1 \\\\ 0.5 & 1 \\end{bmatrix}, \\begin{bmatrix} 1 & 0.5 \\\\ 1 & 1 \\end{bmatrix} $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqW99Bbdpt6e"
      },
      "source": [
        "## <img src=\"https://img.icons8.com/fluency/48/000000/exclamation-mark.png\" style=\"height:50px;display:inline\">  Answer 2 - Layer Normalization\n",
        "---\n",
        "\n",
        "1. Group normalization is equivalent to instance normalization when the group is only one channel. There is only one input channel and thus we don't compute mean and std between the different channels (per example).  \n",
        "2. Group normalization is equivalent to layer normalization when the group is all the channels. Meaning, we calculate the statistics on all channels (per example).  \n",
        "3.  We denote batch size with $N$, amount of channels  with $C$ and width/height of a channel with $W/H$ recpectively. The \"pixels\" matrix per channel is denoted as $P_c$.\n",
        "* Batch Normalization:  \n",
        "  We calculate the mean $\\mu$ vector with respect to the batch size per channel $\\forall i \\in [1,2..C], \\mu_i = \\frac{1}{NWH}\\sum_{n=1}^N \\sum_{l=1}^W \\sum_{m=1}^H P_i[l][m]$ with size of the amount of channels:  \n",
        "$$ \\mu = \\begin{bmatrix} \\mu_1 \\\\ \\mu_2 \\\\ \\mu_3 \\end{bmatrix} = \\begin{bmatrix} \\frac{7.5}{12} \\\\ \\frac{6}{12} \\\\ \\frac{8.5}{12} \\end{bmatrix} = \\begin{bmatrix} \\frac{5}{8} \\\\ \\frac{1}{2} \\\\ 0.7083 \\end{bmatrix} $$ \n",
        "  We subtract the mean from each channel component (in general should divide also with the std) thus the outputs per example:\n",
        "$$ n=1: \\begin{bmatrix} -\\frac{5}{8} & \\frac{3}{8} \\\\ \\frac{3}{8} & -\\frac{5}{8} \\end{bmatrix}, \\begin{bmatrix} \\frac{1}{2} & -\\frac{1}{2} \\\\ -\\frac{1}{2} & \\frac{1}{2} \\end{bmatrix}, \\begin{bmatrix} 0.2917 & 0.2917 \\\\ 0.2917 & 0.2917 \\end{bmatrix} $$\n",
        "\n",
        "$$ n=2: \\begin{bmatrix} -\\frac{1}{8} & -\\frac{1}{8} \\\\ -\\frac{1}{8} & -\\frac{1}{8} \\end{bmatrix}, \\begin{bmatrix} 0 & -\\frac{1}{2} \\\\ 0 & -\\frac{1}{2} \\end{bmatrix}, \\begin{bmatrix} -0.7083 & -0.2183 \\\\ -0.7083 & -0.2183 \\end{bmatrix} $$\n",
        "\n",
        "$$ n=3: \\begin{bmatrix} \\frac{3}{8} & \\frac{3}{8} \\\\ \\frac{3}{8} & -\\frac{1}{8} \\end{bmatrix}, \\begin{bmatrix} 0 & \\frac{1}{2} \\\\ 0 & \\frac{1}{2} \\end{bmatrix}, \\begin{bmatrix} 0.2917 & -0.2183 \\\\ 0.2917 & 0.2917 \\end{bmatrix} $$\n",
        "* Layer Normalization:  \n",
        "  We calculate the mean $\\mu$ vector with respect to the examples dimensions $\\forall i \\in [1,2..N], \\mu_i = \\frac{1}{CWH}\\sum_{c=1}^C \\sum_{l=1}^W \\sum_{m=1}^H P_c[l][m]$:  \n",
        "$$ \\mu = \\begin{bmatrix} \\mu_1 \\\\ \\mu_2 \\\\ \\mu_3 \\end{bmatrix} = \\begin{bmatrix} \\frac{2}{3} \\\\ \\frac{1}{3} \\\\ \\frac{5}{6} \\end{bmatrix}$$ \n",
        "  We subtract the mean from each batch example component (in general should divide also with the std) thus the outputs per example:\n",
        "$$ n=1: \\begin{bmatrix} -\\frac{2}{3} & \\frac{1}{3} \\\\ \\frac{1}{3} & -\\frac{2}{3} \\end{bmatrix}, \\begin{bmatrix} \\frac{1}{3} & -\\frac{2}{3} \\\\ -\\frac{2}{3} & \\frac{1}{3} \\end{bmatrix}, \\begin{bmatrix} \\frac{1}{3} & \\frac{1}{3} \\\\ \\frac{1}{3} & \\frac{1}{3} \\end{bmatrix} $$\n",
        "\n",
        "$$ n=2: \\begin{bmatrix} \\frac{1}{6} & \\frac{1}{6} \\\\ \\frac{1}{6} & \\frac{1}{6} \\end{bmatrix}, \\begin{bmatrix} \\frac{1}{6} & -\\frac{1}{3} \\\\ \\frac{1}{6} & -\\frac{1}{3} \\end{bmatrix}, \\begin{bmatrix} -\\frac{1}{3} & \\frac{1}{6} \\\\ -\\frac{1}{3} & \\frac{1}{6} \\end{bmatrix} $$\n",
        "\n",
        "$$ n=3: \\begin{bmatrix} \\frac{1}{6} & \\frac{1}{6} \\\\ \\frac{1}{6} & -\\frac{1}{3} \\end{bmatrix}, \\begin{bmatrix} -\\frac{1}{3} & \\frac{1}{6} \\\\ -\\frac{1}{3} & \\frac{1}{6} \\end{bmatrix}, \\begin{bmatrix} \\frac{1}{6} & -\\frac{1}{3} \\\\ \\frac{1}{6} & \\frac{1}{6} \\end{bmatrix} $$\n",
        "* Instance Normalization:  \n",
        "  We calculate the mean $\\mu$ vector with respect to the examples dimensions and per channel $\\forall i \\in [1,2..N], \\forall c \\in [1,2..C], \\mu_{i,c} = \\frac{1}{WH}\\sum_{l=1}^W \\sum_{m=1}^H P_c[l][m]$:\n",
        "$$ \\mu = \\begin{bmatrix} \\frac{1}{2} & \\frac{1}{2} & 1 \\\\ \\frac{1}{2} & \\frac{1}{4} & \\frac{1}{4} \\\\ \\frac{7}{8} & \\frac{3}{4} & \\frac{7}{8} \\end{bmatrix}$$ \n",
        "  We subtract the mean from each batch example component per component (in general should divide also with the std) thus the outputs:\n",
        "  $$ n=1: \\begin{bmatrix} -\\frac{1}{2} & \\frac{1}{2} \\\\ \\frac{1}{2} & -\\frac{1}{2} \\end{bmatrix}, \\begin{bmatrix} \\frac{1}{2} & -\\frac{1}{2} \\\\ -\\frac{1}{2} & \\frac{1}{2} \\end{bmatrix}, \\begin{bmatrix} 0 & 0 \\\\ 0 & 0 \\end{bmatrix} $$\n",
        "\n",
        "$$ n=2: \\begin{bmatrix} 0 & 0 \\\\ 0 & 0 \\end{bmatrix}, \\begin{bmatrix} \\frac{1}{4} & -\\frac{1}{4} \\\\ \\frac{1}{4} & -\\frac{1}{4} \\end{bmatrix}, \\begin{bmatrix} -\\frac{1}{4} & \\frac{1}{4} \\\\ -\\frac{1}{4} & \\frac{1}{4} \\end{bmatrix} $$\n",
        "\n",
        "$$ n=3: \\begin{bmatrix} \\frac{1}{8} & \\frac{1}{8} \\\\ \\frac{1}{8} & -\\frac{3}{8} \\end{bmatrix}, \\begin{bmatrix} -\\frac{1}{4} & \\frac{1}{4} \\\\ -\\frac{1}{4} & \\frac{1}{4} \\end{bmatrix}, \\begin{bmatrix} \\frac{1}{8} & -\\frac{3}{8} \\\\ \\frac{1}{8} & \\frac{1}{8} \\end{bmatrix} $$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DqqzLzupt6f"
      },
      "source": [
        "## <img src=\"https://img.icons8.com/clouds/100/000000/question-mark.png\" style=\"height:50px;display:inline\"> Question 3 -Batch Normalization\n",
        "---\n",
        "This question relates to lectures 8-9 (from slide 9):\n",
        "\n",
        "Prove that **without** regularization, BatchNorm **scale invariance** for parameters $\\mathbf{w}$ implies:\n",
        "1. $\\nabla \\mathcal{L}(\\mathbf{w})^T\\mathbf{w} = 0$\n",
        "2. And under gradient flow dynamics ($\\dot{\\mathbf{w}} = -\\eta \\nabla \\mathcal{L}(\\mathbf{w})$) this implies (L2) norm conservation: $\\forall t: ||\\mathbf{w}(t)||^2 = C$\n",
        "\n",
        "Hint: see results from the multilayer networks lecture."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <img src=\"https://img.icons8.com/fluency/48/000000/exclamation-mark.png\" style=\"height:50px;display:inline\">  Answer 3 - Batch Normalization\n",
        "---\n",
        "\n",
        "1. Since the BN layer is invariant to scale of $\\mathbf{w}$ we get:\n",
        "  $\\mathcal{L}(\\mathbf{w})= \\mathcal{L}(\\alpha\\mathbf{w})$\n",
        "  As we saw in lectures, we can build conservation laws if $\\mathcal{L}(\\mathbf{w}) = \\mathcal{L}(\\psi_{\\alpha}\\mathbf{w})$ by applying dervative with respect ot the parameter $\\alpha$:\n",
        "  $$0 \\underbrace{=}_{(1)} \\frac{∂}{∂\\alpha}\\mathcal{L}(\\alpha\\mathbf{w}) = \\nabla \\mathcal{L}(\\alpha\\mathbf{w})^T\\frac{∂}{∂\\alpha}(\\alpha\\mathbf{w}) = \\nabla \\mathcal{L}(\\alpha\\mathbf{w})^T\\mathbf{w} \\underbrace{=}_{(2)} \\nabla \\mathcal{L}(\\mathbf{w})^T\\mathbf{w}$$\n",
        "  When (1) is by applying the derivative with respect to scale $\\alpha$ on both sides of the equation $\\mathcal{L}(\\mathbf{w})= \\mathcal{L}(\\alpha\\mathbf{w})$ and (2) is due to the Loss invarinace with respect to $\\alpha$.  \n",
        "  $\\blacksquare$\n",
        "2. Using the fact that under gradient flow dynamics with small learning rate we have $\\dot{\\mathbf{w}} = -\\eta \\nabla \\mathcal{L}(\\mathbf{w})$, We subtitute the loss gradient in the previous section and apply integration over time:\n",
        "$$ 0 =  \\frac{1}{\\eta}\\nabla \\mathcal{L}(\\mathbf{w})^T\\mathbf{w} = -\\dot{\\mathbf{w}}^T\\mathbf{w} ⇒ 0 =\\dot{\\mathbf{w}}^T\\mathbf{w} ⇒ 0 = \\frac{1}{2}\\frac{d}{dt}||\\mathbf{w}(t)||^2 ⇒ C=||\\mathbf{w}(t)||^2, ∀t$$  \n",
        "  $\\blacksquare$\n"
      ],
      "metadata": {
        "id": "4wjP94VV_de_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7D-14iM7pGhm"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/officel/80/000000/code.png\" style=\"height:50px;display:inline\"> Part 2 - Code Assignments\n",
        "---\n",
        "* You must write your code in this notebook and save it with the output of all of the code cells.\n",
        "* Additional text can be added in Markdown cells.\n",
        "* You can use any other IDE you like (PyCharm, VSCode...) to write/debug your code, but for the submission you must copy it to this notebook, run the code and save the notebook with the output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c_2Lzqcpt6j",
        "outputId": "ece3c744-fbf6-4e9f-8b80-9f15a87a4184"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fcf35e36ab0>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# imports for the practice (you can add more if you need)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import math\n",
        "\n",
        "# pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchtext\n",
        "import torchtext.legacy.data as data\n",
        "import torchtext.legacy.datasets as datasets\n",
        "import torch.nn.functional as f\n",
        "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
        "\n",
        "seed = 211\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRGyWQNypt6l"
      },
      "source": [
        "## <img src=\"https://img.icons8.com/bubbles/50/000000/workflow.png\" style=\"height:50px;display:inline\">  Sequence-to-Sequence with Transformers\n",
        "---\n",
        "* In this exercise, you are going to build a language model using PyTroch's Transformer module.\n",
        "* We will work with the **Wikitext-2** dataset: the WikiText language modeling dataset is a collection of over 100 million tokens extracted from the set of verified Good and Featured articles on Wikipedia.\n",
        "* After training, you will be able to generate senetences!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ay3SD_kopt6m"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/color/48/000000/code.png\" style=\"height:50px;display:inline\"> Task 1  - Loading and Observing the Data\n",
        "---\n",
        "1. Initialize a text `data.Field` using `data.utils.get_tokenizer(\"basic_english\")`, `<sos>` and `<eos>` as start and end tokens, and consider only lower case words (`lower=True`).\n",
        "2. Load the train, valid and test *texts* using `datasets.WikiText2.splits` with your text data field from (1).\n",
        "3. Build a vocabulary using only the train data.\n",
        "4. Create the train, valid and test data using the provided `batchify` function.\n",
        "5. Use the `batchify` function with `batch_size=20` to create a data loader. Print the shape of the result.\n",
        "6. Print 2 train samples. Use the vocabulary you built to transfer between tokens to words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2JhbAT8Mpt6n"
      },
      "outputs": [],
      "source": [
        "def batchify(data, bsz, text_field):\n",
        "    data = text_field.numericalize([data.examples[0].text])\n",
        "    # Divide the dataset into bsz parts.\n",
        "    nbatch = data.size(0) // bsz\n",
        "    # Trim off any extra elements that wouldn't cleanly fit (remainders).\n",
        "    data = data.narrow(0, 0, nbatch * bsz)\n",
        "    # Evenly divide the data across the bsz batches.\n",
        "    data = data.view(bsz, -1).t().contiguous()\n",
        "    return data.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <img src=\"https://img.icons8.com/fluency/48/000000/exclamation-mark.png\" style=\"height:50px;display:inline\">  Task 1 Code and Answers  - Loading and Observing the Data\n",
        "---\n",
        "\n",
        "We have printed 2 samples over the batch dimension (the starting word in each sample after split to batches) and also the sentences parts that (vertical order due to transpose in batchify) start each sample in the batch."
      ],
      "metadata": {
        "id": "_m6etI48Tg31"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syul2ilfpt6o",
        "outputId": "b56cc788-a0b0-41d1-d9e1-85ac211a50d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading wikitext-2-v1.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.48M/4.48M [00:01<00:00, 3.05MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "extracting\n",
            "train size: torch.Size([104335, 20])\n",
            "valid size: torch.Size([10908, 20])\n",
            "test size: torch.Size([12310, 20])\n",
            "\n",
            "2 samples of batch dim:\n",
            "<eos> @ settlement heavy of , , lined the she <unk> of . interception the dried . , would his\n",
            "= 1 was rains ireland and starting with hairy had found the <unk> to possibility heads other which receive gift\n",
            "\n",
            "2 samples of sentences (transposed matrix). cut length to 15:\n",
            "<eos> = valkyria chronicles iii = <eos> <eos> senjō no valkyria 3 <unk> chronicles (\n",
            "@ 1 rebounds , 3 @ . @ 8 assists , and 1 @ .\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Your Code Here\n",
        "\"\"\"\n",
        "\n",
        "BATCH_SIZE = 20\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# define a text field\n",
        "tokenizer = data.utils.get_tokenizer(\"basic_english\")\n",
        "text_field = data.Field(sequential=True, init_token=\"<sos>\", eos_token=\"<eos>\",\n",
        "                  tokenize=tokenizer, lower=True, dtype=torch.long)\n",
        "#datasets.WikiText2.download('./datasets')\n",
        "ds_train, ds_valid, ds_test = datasets.WikiText2.splits(text_field)\n",
        "\n",
        "#print(ds_test.examples[0].text_field[:20])\n",
        "\n",
        "text_field.build_vocab(ds_train)\n",
        "vocab = text_field.vocab\n",
        "\n",
        "train_data = batchify(ds_train, bsz=BATCH_SIZE, text_field=text_field)\n",
        "valid_data = batchify(ds_valid, bsz=BATCH_SIZE, text_field=text_field)\n",
        "test_data = batchify(ds_test, bsz=BATCH_SIZE, text_field=text_field)\n",
        "\n",
        "print(f\"train size: {train_data.size()}\")\n",
        "print(f\"valid size: {valid_data.size()}\")\n",
        "print(f\"test size: {test_data.size()}\")\n",
        "print()\n",
        "\n",
        "def print_batch_dim_sample(data_set, index):\n",
        "  sample_str = \" \".join([vocab.itos[t] for _,t in enumerate(data_set[index].cpu().numpy())])\n",
        "  print(f\"{sample_str}\")\n",
        "\n",
        "def print_sample(data_set, index, num_of_words):\n",
        "  sample_str = \" \".join([vocab.itos[t] for _,t in enumerate(data_set.t()[index][:num_of_words].cpu().numpy())])\n",
        "  print(f\"{sample_str}\")\n",
        "\n",
        "print(\"2 samples of batch dim:\")\n",
        "print_batch_dim_sample(train_data,0)\n",
        "print_batch_dim_sample(train_data,1)\n",
        "\n",
        "print()\n",
        "# we print the first 15 words in each sample after split to batches examples\n",
        "print_len = 15\n",
        "print(f\"2 samples of sentences (transposed matrix). cut length to {print_len}:\")\n",
        "print_sample(train_data,0,print_len)\n",
        "print_sample(train_data,1,print_len)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7hXnCOApt6p"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/color/48/000000/code.png\" style=\"height:50px;display:inline\"> Task 2  - Preparing the  Data - Separating to Inputs and Targets\n",
        "---\n",
        "* For a language modeling task, the model needs the following words as `Target`.\n",
        "    * For example, for the senetence \"I have a nice dog\", the model will be given \"I have a\" as input, and \"nice dog\" as the target.\n",
        "* Implement (complete) the function `get_batch(source, i, bptt)`: it generates the input and target sequence for the transformer model. It subdivides the source data into chunks of length `bptt`.\n",
        "    * For example, for `bptt=2` and at `i=0`, the output of `data, target = get_batch(train_data, i=0, bptt=2)`: `data` will be of shape (2, 20), where the batch size is 20 and `target` will be of length 40 (the target for each element is two words, but we flatten `target`).\n",
        "    * Print a sample from `data` and `target`"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <img src=\"https://img.icons8.com/fluency/48/000000/exclamation-mark.png\" style=\"height:50px;display:inline\">  Task 2 Code and Answers  - Separating to Inputs and Targets\n",
        "---\n",
        "\n",
        "We've split to target that is with one word delay after the input and flattened it. We can see that the second word in each batch match the targets' first words."
      ],
      "metadata": {
        "id": "6UPpynaDLQb8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pb-wXL7pt6q",
        "outputId": "ce3055cc-b229-4e4a-fc52-273c1faa48b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data size is torch.Size([2, 20])\n",
            "target size is torch.Size([40])\n",
            "data sample 0 bare numbers:\n",
            " tensor([    3, 21014,     8,   835,  1283,   220,     9,   197,   195,   123,\n",
            "          737,    11,    20,   911,     8,    77,     5,     0,  1445,    77],\n",
            "       device='cuda:0')\n",
            "data sample 0 in text:\n",
            "<eos> catapult and already bodies league in june due against praised a for decision and up , <unk> coming up\n",
            "\n",
            "data sample 1 bare numbers:\n",
            " tensor([  12,    8,  402, 2358,   69,  510,    4,  392,   10,    0,    4, 3415,\n",
            "           4,  117, 3857,   10,  638,  454, 2613,    9], device='cuda:0')\n",
            "data sample 1 in text:\n",
            "= and service stopped while cup the 2012 to <unk> the stable the early 63 to brought building 11th in\n",
            "\n",
            "target bare numbers:\n",
            " tensor([   12,     8,   402,  2358,    69,   510,     4,   392,    10,     0,\n",
            "            4,  3415,     4,   117,  3857,    10,   638,   454,  2613,     9,\n",
            "          635,    11,  1053,  1067,    16,     5,   117,     5,     0,     0,\n",
            "        12560,   286,  2104,    16,   122,  1082,    10,     6,     8,   293],\n",
            "       device='cuda:0')\n",
            "target in text:\n",
            "= and service stopped while cup the 2012 to <unk> the stable the early 63 to brought building 11th in\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Your Code Here\n",
        "\"\"\"\n",
        "def get_batch(source, i, bptt):\n",
        "    seq_len = min(bptt, len(source) - 1 - i)\n",
        "    data = source[i:i + seq_len]\n",
        "    target = source[(i+1):(i+1+seq_len)].view(-1)\n",
        "    return data, target\n",
        "\n",
        "data, target = get_batch(test_data, i=0, bptt=2)\n",
        "\n",
        "print(f\"data size is {data.size()}\")\n",
        "print(f\"target size is {target.size()}\")\n",
        "\n",
        "print(f\"data sample 0 bare numbers:\\n {data[0]}\")\n",
        "print(f\"data sample 0 in text:\")\n",
        "print_batch_dim_sample(data, 0)\n",
        "print(f\"\\ndata sample 1 bare numbers:\\n {data[1]}\")\n",
        "print(f\"data sample 1 in text:\")\n",
        "print_batch_dim_sample(data, 1)\n",
        "print(f\"\\ntarget bare numbers:\\n {target}\")\n",
        "print(f\"target in text:\")\n",
        "print_batch_dim_sample(target.view(2,20), 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_P7mTE1Kpt6r"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/color/48/000000/code.png\" style=\"height:50px;display:inline\"> Task 3  - Define Hyperparameters and Initialize the Model\n",
        "---\n",
        "* Define the following hyperparameters (`[a, b]` means in the range between `a` and `b`):\n",
        "    * Embedding size: choose from `[200, 250]`\n",
        "    * Number of hidden units: choose from `[200, 250]`\n",
        "    * Number of layers: choose from `[2, 4]`\n",
        "    * Number of attention heads: choose from `[2, 4]`\n",
        "    * Dropout: choose from `[0.0, 0.3]`\n",
        "    * Loss criterion: `nn.CrossEntropyLoss()`\n",
        "    * Optimizer: choose from `[SGD, Adam]`\n",
        "    * Learning rate: choose from `[5e-3, 5.0]`\n",
        "    * Learning Scheduler: `torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)`\n",
        "* Intialize an instance of `TransformerModel` (given) and send it to `device`. Note that you need to give it the number of tokens to define the output of the decoder. You should use the number of tokens in the vocabulary. Print the number of tokens,  print **all** the chosen hyper-parameters and print the model (`print(model`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hEy3ydFVpt6s"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)\n",
        "    \n",
        "class TransformerModel(nn.Module):\n",
        "\n",
        "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
        "        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n",
        "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
        "        self.encoder = nn.Embedding(ntoken, ninp)\n",
        "        self.ninp = ninp\n",
        "        self.decoder = nn.Linear(ninp, ntoken)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "        return mask\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
        "        self.decoder.bias.data.zero_()\n",
        "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        src = self.encoder(src) * math.sqrt(self.ninp)\n",
        "        src = self.pos_encoder(src)\n",
        "        output = self.transformer_encoder(src, src_mask)\n",
        "        output = self.decoder(output)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <img src=\"https://img.icons8.com/fluency/48/000000/exclamation-mark.png\" style=\"height:50px;display:inline\">  Task 3 Code and Answers  - Define Hyperparameters and Initialize the Model\n",
        "---\n",
        "\n",
        "Selcting the hyper parameters, creating the model and print all."
      ],
      "metadata": {
        "id": "PV7qlZ9KMFcI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wGp_Mjnpt6s",
        "outputId": "d83dc8eb-b601-4680-fe03-748d67b2ff48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The hyper parameters:\n",
            "{'EMBED_SIZE': 200, 'HIDDEN_UNITS': 200, 'LAYERS': 2, 'ATTENTION_HEADS': 2, 'DROPOUT': 0.2, 'OPTIMIZER': 'sgd', 'LR': 5.0, 'SCHED_GAMMA': 0.95, 'SCHED_STEP_SIZE': 1.0, 'EPOCHS': 25}\n",
            "The model:\n",
            "TransformerModel(\n",
            "  (pos_encoder): PositionalEncoding(\n",
            "    (dropout): Dropout(p=0.2, inplace=False)\n",
            "  )\n",
            "  (transformer_encoder): TransformerEncoder(\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=200, out_features=200, bias=True)\n",
            "        )\n",
            "        (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "        (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
            "        (norm1): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
            "        (norm2): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout1): Dropout(p=0.2, inplace=False)\n",
            "        (dropout2): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (1): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=200, out_features=200, bias=True)\n",
            "        )\n",
            "        (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "        (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
            "        (norm1): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
            "        (norm2): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout1): Dropout(p=0.2, inplace=False)\n",
            "        (dropout2): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (encoder): Embedding(28785, 200)\n",
            "  (decoder): Linear(in_features=200, out_features=28785, bias=True)\n",
            ")\n",
            "Adjusting learning rate of group 0 to 5.0000e+00.\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Your Code Here\n",
        "\"\"\"\n",
        "hyper_params = {}\n",
        "#Embedding size: choose from `[200, 250]`\n",
        "hyper_params['EMBED_SIZE'] = 200\n",
        "#Number of hidden units: choose from `[200, 250]`\n",
        "hyper_params['HIDDEN_UNITS'] = 200\n",
        "#Number of layers: choose from `[2, 4]`\n",
        "hyper_params['LAYERS'] = 2\n",
        "#Number of attention heads: choose from `[2, 4]`\n",
        "hyper_params['ATTENTION_HEADS'] = 2\n",
        "#Dropout: choose from `[0.0, 0.3]`\n",
        "hyper_params['DROPOUT'] = 0.2\n",
        "#Optimizer: choose from `[SGD, Adam]`\n",
        "hyper_params['OPTIMIZER'] = 'sgd'\n",
        "#Learning rate: choose from `[5e-3, 5.0]`\n",
        "hyper_params['LR'] = 5.0\n",
        "#Learning Scheduler: `torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)`\n",
        "hyper_params['SCHED_GAMMA'] = 0.95\n",
        "hyper_params['SCHED_STEP_SIZE'] = 1.0\n",
        "hyper_params['EPOCHS'] = 25\n",
        "\n",
        "print(\"The hyper parameters:\")\n",
        "print(hyper_params)\n",
        "\n",
        "num_of_tokens = len(text_field.vocab.stoi)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model = TransformerModel(\n",
        "    ntoken=num_of_tokens,\n",
        "    ninp=hyper_params['EMBED_SIZE'],\n",
        "    nhead=hyper_params['ATTENTION_HEADS'],\n",
        "    nhid=hyper_params['HIDDEN_UNITS'],\n",
        "    nlayers=hyper_params['LAYERS'],\n",
        "    dropout=hyper_params['DROPOUT']).to(device)\n",
        "\n",
        "print(\"The model:\")\n",
        "print(model)\n",
        "\n",
        "if hyper_params['OPTIMIZER'] == 'sgd':\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=hyper_params['LR'])\n",
        "else:\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=hyper_params['LR'])\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, hyper_params['SCHED_STEP_SIZE'], gamma=hyper_params['SCHED_GAMMA'], verbose=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDyxvrf3pt6u"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/color/48/000000/code.png\" style=\"height:50px;display:inline\"> Task 4  - Train and Evaluate the Language Model\n",
        "---\n",
        "* Fill in the missing line in the training code and train the model.\n",
        "* Use `bptt=35`.\n",
        "* Use the provided function to evaluate it on the validatation set (after each epoch) and on test test (after training is done). **Print and plot** the results (loss and perplexity).\n",
        "* If you see that the performance does not improve, go back to Task 3 and re-think you hyper-parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rAG9ShgCpt6u"
      },
      "outputs": [],
      "source": [
        "def evaluate(eval_model, data_source):\n",
        "    eval_model.eval() # Turn on the evaluation mode\n",
        "    total_loss = 0.\n",
        "    ntokens = len(text_field.vocab.stoi)\n",
        "    src_mask = model.generate_square_subsequent_mask(bptt).to(device)\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, data_source.size(0) - 1, bptt):\n",
        "            data, targets = get_batch(data_source, i, bptt)\n",
        "            if data.size(0) != bptt:\n",
        "                src_mask = model.generate_square_subsequent_mask(data.size(0)).to(device)\n",
        "            output = eval_model(data, src_mask)\n",
        "            output_flat = output.view(-1, ntokens)\n",
        "            total_loss += len(data) * criterion(output_flat, targets).item()\n",
        "    return total_loss / (len(data_source) - 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <img src=\"https://img.icons8.com/fluency/48/000000/exclamation-mark.png\" style=\"height:50px;display:inline\">  Task 4 Code and Answers  - Train and Evaluate the Language Model\n",
        "---\n"
      ],
      "metadata": {
        "id": "BhI-N5TVfuDw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "DnfPRqgdpt6v"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Your Code Here\n",
        "\"\"\"\n",
        "def train(bptt):\n",
        "    model.train() # Turn on the train mode\n",
        "    total_loss = 0.\n",
        "    start_time = time.time()\n",
        "    ntokens = len(text_field.vocab.stoi)\n",
        "    src_mask = model.generate_square_subsequent_mask(bptt).to(device)\n",
        "    for batch, i in enumerate(range(0, train_data.size(0) - 1, bptt)):\n",
        "        data, targets = get_batch(train_data, i, bptt)\n",
        "        \n",
        "        if data.size(0) != bptt:\n",
        "            src_mask = model.generate_square_subsequent_mask(data.size(0)).to(device)\n",
        "            \n",
        "        output = model(data, src_mask)\n",
        "        loss = criterion(output.view(-1, ntokens), targets)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        log_interval = 200\n",
        "        if batch % log_interval == 0 and batch > 0:\n",
        "            cur_loss = total_loss / log_interval\n",
        "            elapsed = time.time() - start_time\n",
        "            print('| epoch {:3d} | {:5d}/{:5d} batches | '\n",
        "                  'lr {:02.2f} | ms/batch {:5.2f} | '\n",
        "                  'loss {:5.2f} | ppl {:8.2f}'.format(\n",
        "                    epoch, batch, len(train_data) // bptt, scheduler.get_last_lr()[0],\n",
        "                    elapsed * 1000 / log_interval,\n",
        "                    cur_loss, math.exp(cur_loss)))\n",
        "            total_loss = 0\n",
        "            start_time = time.time()\n",
        "\n",
        "def save_checkpoint_model(hyper_params, valid_loss, model, epoch):\n",
        "    torch.save({'hyper_params': hyper_params,\n",
        "                  'valid_loss' : valid_loss,\n",
        "                  'state_dict': model.state_dict()},\n",
        "               f'{epoch}_checkpoint.pth')\n",
        "\n",
        "def load_checkpoint_model(epoch):\n",
        "    filename = f'{epoch}_checkpoint.pth'\n",
        "    checkpoint = torch.load(filename)\n",
        "    loaded_hyper_params = checkpoint['hyper_params']\n",
        "    #print(f\"loaded_hyper_params {loaded_hyper_params}\")\n",
        "    loaded_valid_loss = checkpoint['valid_loss']\n",
        "    loaded_model = TransformerModel(\n",
        "        ntoken=num_of_tokens,\n",
        "        ninp=loaded_hyper_params['EMBED_SIZE'],\n",
        "        nhead=loaded_hyper_params['ATTENTION_HEADS'],\n",
        "        nhid=loaded_hyper_params['HIDDEN_UNITS'],\n",
        "        nlayers=loaded_hyper_params['LAYERS'],\n",
        "        dropout=loaded_hyper_params['DROPOUT']).to(device)\n",
        "    loaded_model.load_state_dict(checkpoint['state_dict'])\n",
        "    return loaded_hyper_params, loaded_valid_loss, loaded_model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The training loop\n",
        "bptt=35\n",
        "valid_losses = []\n",
        "ppls = []\n",
        "min_valid_loss = np.Inf\n",
        "min_loss_epoch = -1\n",
        "\n",
        "for epoch in np.arange(1, hyper_params['EPOCHS'] + 1):\n",
        "\n",
        "    e_start_time = time.time()\n",
        "    train(bptt)\n",
        "    valid_loss = evaluate(model, valid_data)\n",
        "    valid_losses.append(valid_loss)\n",
        "\n",
        "    ppl = np.exp(valid_loss)\n",
        "    ppls.append(ppl)\n",
        "\n",
        "    epoch_elapsed = time.time() - e_start_time\n",
        "\n",
        "    print(f\"| *** done epoch {epoch} | valid loss {valid_loss:5.4f} | ppl {ppl:8.2f} | elapsed {epoch_elapsed}\")\n",
        "\n",
        "    if valid_loss < min_valid_loss:\n",
        "        print('==> Saving checkpoint for the lowest validation loss model ...', end =\" \")\n",
        "        save_checkpoint_model(hyper_params, valid_loss, model, epoch)\n",
        "        print(\"Done saving\")      \n",
        "        min_loss_epoch = epoch\n",
        "        min_valid_loss = valid_loss\n",
        "\n",
        "    scheduler.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMFXBVScmBzX",
        "outputId": "a3676960-9d30-4e55-d507-d56076335f9a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |   200/ 2981 batches | lr 5.00 | ms/batch 36.79 | loss  8.04 | ppl  3101.84\n",
            "| epoch   1 |   400/ 2981 batches | lr 5.00 | ms/batch 35.20 | loss  6.81 | ppl   904.24\n",
            "| epoch   1 |   600/ 2981 batches | lr 5.00 | ms/batch 35.29 | loss  6.37 | ppl   585.15\n",
            "| epoch   1 |   800/ 2981 batches | lr 5.00 | ms/batch 35.25 | loss  6.23 | ppl   510.19\n",
            "| epoch   1 |  1000/ 2981 batches | lr 5.00 | ms/batch 35.38 | loss  6.13 | ppl   457.52\n",
            "| epoch   1 |  1200/ 2981 batches | lr 5.00 | ms/batch 35.56 | loss  6.09 | ppl   440.83\n",
            "| epoch   1 |  1400/ 2981 batches | lr 5.00 | ms/batch 35.52 | loss  6.04 | ppl   418.03\n",
            "| epoch   1 |  1600/ 2981 batches | lr 5.00 | ms/batch 35.48 | loss  6.05 | ppl   423.50\n",
            "| epoch   1 |  1800/ 2981 batches | lr 5.00 | ms/batch 35.74 | loss  5.96 | ppl   388.52\n",
            "| epoch   1 |  2000/ 2981 batches | lr 5.00 | ms/batch 35.82 | loss  5.96 | ppl   386.23\n",
            "| epoch   1 |  2200/ 2981 batches | lr 5.00 | ms/batch 36.17 | loss  5.85 | ppl   347.26\n",
            "| epoch   1 |  2400/ 2981 batches | lr 5.00 | ms/batch 36.39 | loss  5.89 | ppl   362.45\n",
            "| epoch   1 |  2600/ 2981 batches | lr 5.00 | ms/batch 35.93 | loss  5.90 | ppl   365.28\n",
            "| epoch   1 |  2800/ 2981 batches | lr 5.00 | ms/batch 36.03 | loss  5.80 | ppl   331.57\n",
            "| *** done epoch 1 | valid loss 5.7094 | ppl   301.69 | elapsed 109.94012093544006\n",
            "==> Saving checkpoint for the lowest validation loss model ... Done saving\n",
            "Adjusting learning rate of group 0 to 4.7500e+00.\n",
            "| epoch   2 |   200/ 2981 batches | lr 4.75 | ms/batch 36.21 | loss  5.80 | ppl   331.42\n",
            "| epoch   2 |   400/ 2981 batches | lr 4.75 | ms/batch 36.08 | loss  5.77 | ppl   321.97\n",
            "| epoch   2 |   600/ 2981 batches | lr 4.75 | ms/batch 36.17 | loss  5.61 | ppl   273.54\n",
            "| epoch   2 |   800/ 2981 batches | lr 4.75 | ms/batch 35.89 | loss  5.63 | ppl   277.73\n",
            "| epoch   2 |  1000/ 2981 batches | lr 4.75 | ms/batch 35.92 | loss  5.59 | ppl   266.55\n",
            "| epoch   2 |  1200/ 2981 batches | lr 4.75 | ms/batch 36.02 | loss  5.61 | ppl   272.40\n",
            "| epoch   2 |  1400/ 2981 batches | lr 4.75 | ms/batch 35.88 | loss  5.62 | ppl   275.04\n",
            "| epoch   2 |  1600/ 2981 batches | lr 4.75 | ms/batch 35.89 | loss  5.65 | ppl   283.44\n",
            "| epoch   2 |  1800/ 2981 batches | lr 4.75 | ms/batch 35.83 | loss  5.59 | ppl   266.42\n",
            "| epoch   2 |  2000/ 2981 batches | lr 4.75 | ms/batch 35.86 | loss  5.61 | ppl   274.15\n",
            "| epoch   2 |  2200/ 2981 batches | lr 4.75 | ms/batch 35.79 | loss  5.50 | ppl   245.19\n",
            "| epoch   2 |  2400/ 2981 batches | lr 4.75 | ms/batch 35.88 | loss  5.57 | ppl   262.99\n",
            "| epoch   2 |  2600/ 2981 batches | lr 4.75 | ms/batch 36.00 | loss  5.59 | ppl   267.25\n",
            "| epoch   2 |  2800/ 2981 batches | lr 4.75 | ms/batch 35.95 | loss  5.51 | ppl   246.52\n",
            "| *** done epoch 2 | valid loss 5.6106 | ppl   273.30 | elapsed 110.4652636051178\n",
            "==> Saving checkpoint for the lowest validation loss model ... Done saving\n",
            "Adjusting learning rate of group 0 to 4.5125e+00.\n",
            "| epoch   3 |   200/ 2981 batches | lr 4.51 | ms/batch 36.00 | loss  5.54 | ppl   254.43\n",
            "| epoch   3 |   400/ 2981 batches | lr 4.51 | ms/batch 35.83 | loss  5.55 | ppl   256.49\n",
            "| epoch   3 |   600/ 2981 batches | lr 4.51 | ms/batch 35.94 | loss  5.36 | ppl   213.17\n",
            "| epoch   3 |   800/ 2981 batches | lr 4.51 | ms/batch 35.91 | loss  5.41 | ppl   223.52\n",
            "| epoch   3 |  1000/ 2981 batches | lr 4.51 | ms/batch 35.97 | loss  5.37 | ppl   215.07\n",
            "| epoch   3 |  1200/ 2981 batches | lr 4.51 | ms/batch 35.92 | loss  5.41 | ppl   223.54\n",
            "| epoch   3 |  1400/ 2981 batches | lr 4.51 | ms/batch 35.78 | loss  5.42 | ppl   226.68\n",
            "| epoch   3 |  1600/ 2981 batches | lr 4.51 | ms/batch 35.83 | loss  5.47 | ppl   236.57\n",
            "| epoch   3 |  1800/ 2981 batches | lr 4.51 | ms/batch 35.90 | loss  5.41 | ppl   222.89\n",
            "| epoch   3 |  2000/ 2981 batches | lr 4.51 | ms/batch 35.81 | loss  5.43 | ppl   228.66\n",
            "| epoch   3 |  2200/ 2981 batches | lr 4.51 | ms/batch 35.87 | loss  5.32 | ppl   203.45\n",
            "| epoch   3 |  2400/ 2981 batches | lr 4.51 | ms/batch 36.02 | loss  5.39 | ppl   218.74\n",
            "| epoch   3 |  2600/ 2981 batches | lr 4.51 | ms/batch 36.10 | loss  5.40 | ppl   220.46\n",
            "| epoch   3 |  2800/ 2981 batches | lr 4.51 | ms/batch 35.87 | loss  5.33 | ppl   206.52\n",
            "| *** done epoch 3 | valid loss 5.5154 | ppl   248.49 | elapsed 110.31831169128418\n",
            "==> Saving checkpoint for the lowest validation loss model ... Done saving\n",
            "Adjusting learning rate of group 0 to 4.2869e+00.\n",
            "| epoch   4 |   200/ 2981 batches | lr 4.29 | ms/batch 35.94 | loss  5.38 | ppl   216.21\n",
            "| epoch   4 |   400/ 2981 batches | lr 4.29 | ms/batch 35.83 | loss  5.39 | ppl   218.12\n",
            "| epoch   4 |   600/ 2981 batches | lr 4.29 | ms/batch 35.82 | loss  5.20 | ppl   180.51\n",
            "| epoch   4 |   800/ 2981 batches | lr 4.29 | ms/batch 35.69 | loss  5.26 | ppl   192.21\n",
            "| epoch   4 |  1000/ 2981 batches | lr 4.29 | ms/batch 35.83 | loss  5.22 | ppl   184.90\n",
            "| epoch   4 |  1200/ 2981 batches | lr 4.29 | ms/batch 35.95 | loss  5.26 | ppl   192.75\n",
            "| epoch   4 |  1400/ 2981 batches | lr 4.29 | ms/batch 35.75 | loss  5.30 | ppl   199.66\n",
            "| epoch   4 |  1600/ 2981 batches | lr 4.29 | ms/batch 35.84 | loss  5.33 | ppl   207.05\n",
            "| epoch   4 |  1800/ 2981 batches | lr 4.29 | ms/batch 35.84 | loss  5.27 | ppl   195.14\n",
            "| epoch   4 |  2000/ 2981 batches | lr 4.29 | ms/batch 35.80 | loss  5.30 | ppl   199.56\n",
            "| epoch   4 |  2200/ 2981 batches | lr 4.29 | ms/batch 35.73 | loss  5.17 | ppl   176.37\n",
            "| epoch   4 |  2400/ 2981 batches | lr 4.29 | ms/batch 35.82 | loss  5.26 | ppl   192.03\n",
            "| epoch   4 |  2600/ 2981 batches | lr 4.29 | ms/batch 35.69 | loss  5.27 | ppl   195.02\n",
            "| epoch   4 |  2800/ 2981 batches | lr 4.29 | ms/batch 35.83 | loss  5.21 | ppl   182.96\n",
            "| *** done epoch 4 | valid loss 5.4917 | ppl   242.66 | elapsed 110.05525159835815\n",
            "==> Saving checkpoint for the lowest validation loss model ... Done saving\n",
            "Adjusting learning rate of group 0 to 4.0725e+00.\n",
            "| epoch   5 |   200/ 2981 batches | lr 4.07 | ms/batch 36.01 | loss  5.25 | ppl   190.25\n",
            "| epoch   5 |   400/ 2981 batches | lr 4.07 | ms/batch 35.91 | loss  5.26 | ppl   193.26\n",
            "| epoch   5 |   600/ 2981 batches | lr 4.07 | ms/batch 35.79 | loss  5.08 | ppl   160.51\n",
            "| epoch   5 |   800/ 2981 batches | lr 4.07 | ms/batch 35.81 | loss  5.14 | ppl   169.94\n",
            "| epoch   5 |  1000/ 2981 batches | lr 4.07 | ms/batch 35.84 | loss  5.10 | ppl   164.68\n",
            "| epoch   5 |  1200/ 2981 batches | lr 4.07 | ms/batch 35.88 | loss  5.15 | ppl   171.85\n",
            "| epoch   5 |  1400/ 2981 batches | lr 4.07 | ms/batch 35.80 | loss  5.17 | ppl   176.10\n",
            "| epoch   5 |  1600/ 2981 batches | lr 4.07 | ms/batch 35.94 | loss  5.21 | ppl   183.79\n",
            "| epoch   5 |  1800/ 2981 batches | lr 4.07 | ms/batch 35.86 | loss  5.16 | ppl   174.45\n",
            "| epoch   5 |  2000/ 2981 batches | lr 4.07 | ms/batch 35.82 | loss  5.19 | ppl   178.84\n",
            "| epoch   5 |  2200/ 2981 batches | lr 4.07 | ms/batch 35.80 | loss  5.06 | ppl   158.16\n",
            "| epoch   5 |  2400/ 2981 batches | lr 4.07 | ms/batch 35.74 | loss  5.15 | ppl   171.68\n",
            "| epoch   5 |  2600/ 2981 batches | lr 4.07 | ms/batch 35.76 | loss  5.16 | ppl   174.96\n",
            "| epoch   5 |  2800/ 2981 batches | lr 4.07 | ms/batch 35.80 | loss  5.11 | ppl   164.95\n",
            "| *** done epoch 5 | valid loss 5.4422 | ppl   230.95 | elapsed 110.1341233253479\n",
            "==> Saving checkpoint for the lowest validation loss model ... Done saving\n",
            "Adjusting learning rate of group 0 to 3.8689e+00.\n",
            "| epoch   6 |   200/ 2981 batches | lr 3.87 | ms/batch 36.01 | loss  5.15 | ppl   172.25\n",
            "| epoch   6 |   400/ 2981 batches | lr 3.87 | ms/batch 35.80 | loss  5.16 | ppl   174.77\n",
            "| epoch   6 |   600/ 2981 batches | lr 3.87 | ms/batch 35.78 | loss  4.97 | ppl   144.47\n",
            "| epoch   6 |   800/ 2981 batches | lr 3.87 | ms/batch 35.71 | loss  5.03 | ppl   153.47\n",
            "| epoch   6 |  1000/ 2981 batches | lr 3.87 | ms/batch 35.83 | loss  5.01 | ppl   150.52\n",
            "| epoch   6 |  1200/ 2981 batches | lr 3.87 | ms/batch 35.77 | loss  5.05 | ppl   155.73\n",
            "| epoch   6 |  1400/ 2981 batches | lr 3.87 | ms/batch 35.79 | loss  5.08 | ppl   160.68\n",
            "| epoch   6 |  1600/ 2981 batches | lr 3.87 | ms/batch 35.86 | loss  5.12 | ppl   167.09\n",
            "| epoch   6 |  1800/ 2981 batches | lr 3.87 | ms/batch 35.78 | loss  5.07 | ppl   159.28\n",
            "| epoch   6 |  2000/ 2981 batches | lr 3.87 | ms/batch 35.79 | loss  5.09 | ppl   162.13\n",
            "| epoch   6 |  2200/ 2981 batches | lr 3.87 | ms/batch 35.81 | loss  4.96 | ppl   142.55\n",
            "| epoch   6 |  2400/ 2981 batches | lr 3.87 | ms/batch 35.79 | loss  5.05 | ppl   155.29\n",
            "| epoch   6 |  2600/ 2981 batches | lr 3.87 | ms/batch 35.79 | loss  5.07 | ppl   159.08\n",
            "| epoch   6 |  2800/ 2981 batches | lr 3.87 | ms/batch 35.72 | loss  5.01 | ppl   149.18\n",
            "| *** done epoch 6 | valid loss 5.4072 | ppl   223.00 | elapsed 110.02639675140381\n",
            "==> Saving checkpoint for the lowest validation loss model ... Done saving\n",
            "Adjusting learning rate of group 0 to 3.6755e+00.\n",
            "| epoch   7 |   200/ 2981 batches | lr 3.68 | ms/batch 36.13 | loss  5.05 | ppl   155.47\n",
            "| epoch   7 |   400/ 2981 batches | lr 3.68 | ms/batch 35.88 | loss  5.08 | ppl   160.13\n",
            "| epoch   7 |   600/ 2981 batches | lr 3.68 | ms/batch 35.93 | loss  4.88 | ppl   132.17\n",
            "| epoch   7 |   800/ 2981 batches | lr 3.68 | ms/batch 35.62 | loss  4.95 | ppl   141.34\n",
            "| epoch   7 |  1000/ 2981 batches | lr 3.68 | ms/batch 35.92 | loss  4.93 | ppl   137.81\n",
            "| epoch   7 |  1200/ 2981 batches | lr 3.68 | ms/batch 35.75 | loss  4.96 | ppl   142.79\n",
            "| epoch   7 |  1400/ 2981 batches | lr 3.68 | ms/batch 35.79 | loss  4.99 | ppl   146.30\n",
            "| epoch   7 |  1600/ 2981 batches | lr 3.68 | ms/batch 35.79 | loss  5.04 | ppl   154.01\n",
            "| epoch   7 |  1800/ 2981 batches | lr 3.68 | ms/batch 35.71 | loss  5.00 | ppl   147.91\n",
            "| epoch   7 |  2000/ 2981 batches | lr 3.68 | ms/batch 35.80 | loss  5.01 | ppl   150.30\n",
            "| epoch   7 |  2200/ 2981 batches | lr 3.68 | ms/batch 35.93 | loss  4.88 | ppl   131.09\n",
            "| epoch   7 |  2400/ 2981 batches | lr 3.68 | ms/batch 35.87 | loss  4.96 | ppl   142.75\n",
            "| epoch   7 |  2600/ 2981 batches | lr 3.68 | ms/batch 35.84 | loss  4.98 | ppl   146.20\n",
            "| epoch   7 |  2800/ 2981 batches | lr 3.68 | ms/batch 35.84 | loss  4.92 | ppl   137.38\n",
            "| *** done epoch 7 | valid loss 5.4237 | ppl   226.71 | elapsed 110.15695691108704\n",
            "Adjusting learning rate of group 0 to 3.4917e+00.\n",
            "| epoch   8 |   200/ 2981 batches | lr 3.49 | ms/batch 36.04 | loss  4.97 | ppl   144.25\n",
            "| epoch   8 |   400/ 2981 batches | lr 3.49 | ms/batch 35.82 | loss  4.99 | ppl   147.48\n",
            "| epoch   8 |   600/ 2981 batches | lr 3.49 | ms/batch 35.80 | loss  4.81 | ppl   122.47\n",
            "| epoch   8 |   800/ 2981 batches | lr 3.49 | ms/batch 35.81 | loss  4.87 | ppl   130.27\n",
            "| epoch   8 |  1000/ 2981 batches | lr 3.49 | ms/batch 35.70 | loss  4.85 | ppl   128.21\n",
            "| epoch   8 |  1200/ 2981 batches | lr 3.49 | ms/batch 35.88 | loss  4.89 | ppl   132.46\n",
            "| epoch   8 |  1400/ 2981 batches | lr 3.49 | ms/batch 35.81 | loss  4.91 | ppl   136.22\n",
            "| epoch   8 |  1600/ 2981 batches | lr 3.49 | ms/batch 35.78 | loss  4.97 | ppl   143.92\n",
            "| epoch   8 |  1800/ 2981 batches | lr 3.49 | ms/batch 35.78 | loss  4.92 | ppl   136.64\n",
            "| epoch   8 |  2000/ 2981 batches | lr 3.49 | ms/batch 35.91 | loss  4.93 | ppl   138.82\n",
            "| epoch   8 |  2200/ 2981 batches | lr 3.49 | ms/batch 35.78 | loss  4.79 | ppl   120.50\n",
            "| epoch   8 |  2400/ 2981 batches | lr 3.49 | ms/batch 35.92 | loss  4.89 | ppl   132.81\n",
            "| epoch   8 |  2600/ 2981 batches | lr 3.49 | ms/batch 35.80 | loss  4.92 | ppl   136.50\n",
            "| epoch   8 |  2800/ 2981 batches | lr 3.49 | ms/batch 35.69 | loss  4.85 | ppl   127.13\n",
            "| *** done epoch 8 | valid loss 5.4594 | ppl   234.95 | elapsed 110.07212710380554\n",
            "Adjusting learning rate of group 0 to 3.3171e+00.\n",
            "| epoch   9 |   200/ 2981 batches | lr 3.32 | ms/batch 36.08 | loss  4.90 | ppl   134.11\n",
            "| epoch   9 |   400/ 2981 batches | lr 3.32 | ms/batch 35.97 | loss  4.92 | ppl   136.96\n",
            "| epoch   9 |   600/ 2981 batches | lr 3.32 | ms/batch 35.86 | loss  4.74 | ppl   114.49\n",
            "| epoch   9 |   800/ 2981 batches | lr 3.32 | ms/batch 35.75 | loss  4.80 | ppl   121.99\n",
            "| epoch   9 |  1000/ 2981 batches | lr 3.32 | ms/batch 35.82 | loss  4.79 | ppl   120.26\n",
            "| epoch   9 |  1200/ 2981 batches | lr 3.32 | ms/batch 35.72 | loss  4.83 | ppl   124.62\n",
            "| epoch   9 |  1400/ 2981 batches | lr 3.32 | ms/batch 35.66 | loss  4.84 | ppl   126.82\n",
            "| epoch   9 |  1600/ 2981 batches | lr 3.32 | ms/batch 35.89 | loss  4.90 | ppl   134.06\n",
            "| epoch   9 |  1800/ 2981 batches | lr 3.32 | ms/batch 35.74 | loss  4.84 | ppl   127.05\n",
            "| epoch   9 |  2000/ 2981 batches | lr 3.32 | ms/batch 35.62 | loss  4.87 | ppl   129.81\n",
            "| epoch   9 |  2200/ 2981 batches | lr 3.32 | ms/batch 35.74 | loss  4.72 | ppl   112.25\n",
            "| epoch   9 |  2400/ 2981 batches | lr 3.32 | ms/batch 35.76 | loss  4.82 | ppl   123.79\n",
            "| epoch   9 |  2600/ 2981 batches | lr 3.32 | ms/batch 35.74 | loss  4.85 | ppl   127.21\n",
            "| epoch   9 |  2800/ 2981 batches | lr 3.32 | ms/batch 35.76 | loss  4.79 | ppl   119.86\n",
            "| *** done epoch 9 | valid loss 5.4380 | ppl   229.99 | elapsed 109.97229480743408\n",
            "Adjusting learning rate of group 0 to 3.1512e+00.\n",
            "| epoch  10 |   200/ 2981 batches | lr 3.15 | ms/batch 35.91 | loss  4.84 | ppl   125.85\n",
            "| epoch  10 |   400/ 2981 batches | lr 3.15 | ms/batch 35.77 | loss  4.86 | ppl   128.51\n",
            "| epoch  10 |   600/ 2981 batches | lr 3.15 | ms/batch 35.73 | loss  4.68 | ppl   107.31\n",
            "| epoch  10 |   800/ 2981 batches | lr 3.15 | ms/batch 35.68 | loss  4.74 | ppl   114.33\n",
            "| epoch  10 |  1000/ 2981 batches | lr 3.15 | ms/batch 35.57 | loss  4.72 | ppl   112.46\n",
            "| epoch  10 |  1200/ 2981 batches | lr 3.15 | ms/batch 35.78 | loss  4.76 | ppl   116.82\n",
            "| epoch  10 |  1400/ 2981 batches | lr 3.15 | ms/batch 35.70 | loss  4.78 | ppl   119.38\n",
            "| epoch  10 |  1600/ 2981 batches | lr 3.15 | ms/batch 35.70 | loss  4.83 | ppl   125.45\n",
            "| epoch  10 |  1800/ 2981 batches | lr 3.15 | ms/batch 35.84 | loss  4.79 | ppl   120.42\n",
            "| epoch  10 |  2000/ 2981 batches | lr 3.15 | ms/batch 35.81 | loss  4.80 | ppl   121.04\n",
            "| epoch  10 |  2200/ 2981 batches | lr 3.15 | ms/batch 35.68 | loss  4.67 | ppl   106.38\n",
            "| epoch  10 |  2400/ 2981 batches | lr 3.15 | ms/batch 35.61 | loss  4.75 | ppl   115.16\n",
            "| epoch  10 |  2600/ 2981 batches | lr 3.15 | ms/batch 35.78 | loss  4.78 | ppl   119.16\n",
            "| epoch  10 |  2800/ 2981 batches | lr 3.15 | ms/batch 35.72 | loss  4.71 | ppl   111.54\n",
            "| *** done epoch 10 | valid loss 5.4227 | ppl   226.49 | elapsed 109.84501695632935\n",
            "Adjusting learning rate of group 0 to 2.9937e+00.\n",
            "| epoch  11 |   200/ 2981 batches | lr 2.99 | ms/batch 35.84 | loss  4.77 | ppl   117.98\n",
            "| epoch  11 |   400/ 2981 batches | lr 2.99 | ms/batch 35.79 | loss  4.80 | ppl   121.73\n",
            "| epoch  11 |   600/ 2981 batches | lr 2.99 | ms/batch 35.62 | loss  4.62 | ppl   101.28\n",
            "| epoch  11 |   800/ 2981 batches | lr 2.99 | ms/batch 35.65 | loss  4.68 | ppl   108.17\n",
            "| epoch  11 |  1000/ 2981 batches | lr 2.99 | ms/batch 35.64 | loss  4.66 | ppl   105.99\n",
            "| epoch  11 |  1200/ 2981 batches | lr 2.99 | ms/batch 35.77 | loss  4.70 | ppl   110.44\n",
            "| epoch  11 |  1400/ 2981 batches | lr 2.99 | ms/batch 35.81 | loss  4.72 | ppl   112.60\n",
            "| epoch  11 |  1600/ 2981 batches | lr 2.99 | ms/batch 36.00 | loss  4.77 | ppl   118.29\n",
            "| epoch  11 |  1800/ 2981 batches | lr 2.99 | ms/batch 35.78 | loss  4.74 | ppl   113.99\n",
            "| epoch  11 |  2000/ 2981 batches | lr 2.99 | ms/batch 35.70 | loss  4.74 | ppl   114.87\n",
            "| epoch  11 |  2200/ 2981 batches | lr 2.99 | ms/batch 35.76 | loss  4.60 | ppl    99.88\n",
            "| epoch  11 |  2400/ 2981 batches | lr 2.99 | ms/batch 35.72 | loss  4.69 | ppl   109.04\n",
            "| epoch  11 |  2600/ 2981 batches | lr 2.99 | ms/batch 35.74 | loss  4.72 | ppl   111.99\n",
            "| epoch  11 |  2800/ 2981 batches | lr 2.99 | ms/batch 35.74 | loss  4.66 | ppl   105.91\n",
            "| *** done epoch 11 | valid loss 5.4452 | ppl   231.64 | elapsed 109.9046835899353\n",
            "Adjusting learning rate of group 0 to 2.8440e+00.\n",
            "| epoch  12 |   200/ 2981 batches | lr 2.84 | ms/batch 35.99 | loss  4.71 | ppl   111.39\n",
            "| epoch  12 |   400/ 2981 batches | lr 2.84 | ms/batch 35.65 | loss  4.74 | ppl   114.46\n",
            "| epoch  12 |   600/ 2981 batches | lr 2.84 | ms/batch 35.75 | loss  4.56 | ppl    95.68\n",
            "| epoch  12 |   800/ 2981 batches | lr 2.84 | ms/batch 35.81 | loss  4.63 | ppl   102.26\n",
            "| epoch  12 |  1000/ 2981 batches | lr 2.84 | ms/batch 35.86 | loss  4.62 | ppl   101.30\n",
            "| epoch  12 |  1200/ 2981 batches | lr 2.84 | ms/batch 35.92 | loss  4.65 | ppl   104.52\n",
            "| epoch  12 |  1400/ 2981 batches | lr 2.84 | ms/batch 35.84 | loss  4.67 | ppl   106.17\n",
            "| epoch  12 |  1600/ 2981 batches | lr 2.84 | ms/batch 35.81 | loss  4.72 | ppl   111.96\n",
            "| epoch  12 |  1800/ 2981 batches | lr 2.84 | ms/batch 35.99 | loss  4.68 | ppl   107.77\n",
            "| epoch  12 |  2000/ 2981 batches | lr 2.84 | ms/batch 35.90 | loss  4.68 | ppl   108.17\n",
            "| epoch  12 |  2200/ 2981 batches | lr 2.84 | ms/batch 35.81 | loss  4.55 | ppl    94.85\n",
            "| epoch  12 |  2400/ 2981 batches | lr 2.84 | ms/batch 35.71 | loss  4.63 | ppl   102.96\n",
            "| epoch  12 |  2600/ 2981 batches | lr 2.84 | ms/batch 35.77 | loss  4.66 | ppl   105.74\n",
            "| epoch  12 |  2800/ 2981 batches | lr 2.84 | ms/batch 35.73 | loss  4.61 | ppl   100.36\n",
            "| *** done epoch 12 | valid loss 5.4569 | ppl   234.37 | elapsed 110.05356192588806\n",
            "Adjusting learning rate of group 0 to 2.7018e+00.\n",
            "| epoch  13 |   200/ 2981 batches | lr 2.70 | ms/batch 35.99 | loss  4.66 | ppl   105.57\n",
            "| epoch  13 |   400/ 2981 batches | lr 2.70 | ms/batch 35.79 | loss  4.69 | ppl   108.61\n",
            "| epoch  13 |   600/ 2981 batches | lr 2.70 | ms/batch 35.65 | loss  4.51 | ppl    91.11\n",
            "| epoch  13 |   800/ 2981 batches | lr 2.70 | ms/batch 35.74 | loss  4.57 | ppl    96.83\n",
            "| epoch  13 |  1000/ 2981 batches | lr 2.70 | ms/batch 35.79 | loss  4.57 | ppl    96.27\n",
            "| epoch  13 |  1200/ 2981 batches | lr 2.70 | ms/batch 35.64 | loss  4.60 | ppl    99.57\n",
            "| epoch  13 |  1400/ 2981 batches | lr 2.70 | ms/batch 35.85 | loss  4.62 | ppl   101.02\n",
            "| epoch  13 |  1600/ 2981 batches | lr 2.70 | ms/batch 35.89 | loss  4.67 | ppl   106.53\n",
            "| epoch  13 |  1800/ 2981 batches | lr 2.70 | ms/batch 35.87 | loss  4.63 | ppl   102.68\n",
            "| epoch  13 |  2000/ 2981 batches | lr 2.70 | ms/batch 35.94 | loss  4.64 | ppl   103.45\n",
            "| epoch  13 |  2200/ 2981 batches | lr 2.70 | ms/batch 35.89 | loss  4.50 | ppl    90.19\n",
            "| epoch  13 |  2400/ 2981 batches | lr 2.70 | ms/batch 35.72 | loss  4.59 | ppl    98.16\n",
            "| epoch  13 |  2600/ 2981 batches | lr 2.70 | ms/batch 35.70 | loss  4.62 | ppl   101.20\n",
            "| epoch  13 |  2800/ 2981 batches | lr 2.70 | ms/batch 35.84 | loss  4.56 | ppl    95.86\n",
            "| *** done epoch 13 | valid loss 5.4636 | ppl   235.94 | elapsed 110.03865361213684\n",
            "Adjusting learning rate of group 0 to 2.5667e+00.\n",
            "| epoch  14 |   200/ 2981 batches | lr 2.57 | ms/batch 36.01 | loss  4.62 | ppl   101.01\n",
            "| epoch  14 |   400/ 2981 batches | lr 2.57 | ms/batch 35.87 | loss  4.63 | ppl   102.97\n",
            "| epoch  14 |   600/ 2981 batches | lr 2.57 | ms/batch 35.77 | loss  4.47 | ppl    87.69\n",
            "| epoch  14 |   800/ 2981 batches | lr 2.57 | ms/batch 35.78 | loss  4.52 | ppl    92.21\n",
            "| epoch  14 |  1000/ 2981 batches | lr 2.57 | ms/batch 35.71 | loss  4.52 | ppl    92.23\n",
            "| epoch  14 |  1200/ 2981 batches | lr 2.57 | ms/batch 35.72 | loss  4.55 | ppl    95.08\n",
            "| epoch  14 |  1400/ 2981 batches | lr 2.57 | ms/batch 35.61 | loss  4.57 | ppl    96.52\n",
            "| epoch  14 |  1600/ 2981 batches | lr 2.57 | ms/batch 35.77 | loss  4.62 | ppl   101.28\n",
            "| epoch  14 |  1800/ 2981 batches | lr 2.57 | ms/batch 35.83 | loss  4.58 | ppl    97.89\n",
            "| epoch  14 |  2000/ 2981 batches | lr 2.57 | ms/batch 35.71 | loss  4.59 | ppl    98.79\n",
            "| epoch  14 |  2200/ 2981 batches | lr 2.57 | ms/batch 35.87 | loss  4.46 | ppl    86.36\n",
            "| epoch  14 |  2400/ 2981 batches | lr 2.57 | ms/batch 35.75 | loss  4.54 | ppl    93.66\n",
            "| epoch  14 |  2600/ 2981 batches | lr 2.57 | ms/batch 35.73 | loss  4.56 | ppl    95.25\n",
            "| epoch  14 |  2800/ 2981 batches | lr 2.57 | ms/batch 35.71 | loss  4.51 | ppl    90.97\n",
            "| *** done epoch 14 | valid loss 5.4868 | ppl   241.49 | elapsed 109.94543814659119\n",
            "Adjusting learning rate of group 0 to 2.4384e+00.\n",
            "| epoch  15 |   200/ 2981 batches | lr 2.44 | ms/batch 36.06 | loss  4.57 | ppl    96.32\n",
            "| epoch  15 |   400/ 2981 batches | lr 2.44 | ms/batch 35.75 | loss  4.59 | ppl    98.80\n",
            "| epoch  15 |   600/ 2981 batches | lr 2.44 | ms/batch 35.78 | loss  4.43 | ppl    83.80\n",
            "| epoch  15 |   800/ 2981 batches | lr 2.44 | ms/batch 35.75 | loss  4.48 | ppl    88.63\n",
            "| epoch  15 |  1000/ 2981 batches | lr 2.44 | ms/batch 35.73 | loss  4.48 | ppl    88.41\n",
            "| epoch  15 |  1200/ 2981 batches | lr 2.44 | ms/batch 35.84 | loss  4.52 | ppl    91.38\n",
            "| epoch  15 |  1400/ 2981 batches | lr 2.44 | ms/batch 35.72 | loss  4.53 | ppl    92.81\n",
            "| epoch  15 |  1600/ 2981 batches | lr 2.44 | ms/batch 35.75 | loss  4.58 | ppl    97.34\n",
            "| epoch  15 |  1800/ 2981 batches | lr 2.44 | ms/batch 35.88 | loss  4.54 | ppl    93.90\n",
            "| epoch  15 |  2000/ 2981 batches | lr 2.44 | ms/batch 35.77 | loss  4.55 | ppl    94.58\n",
            "| epoch  15 |  2200/ 2981 batches | lr 2.44 | ms/batch 35.67 | loss  4.42 | ppl    82.81\n",
            "| epoch  15 |  2400/ 2981 batches | lr 2.44 | ms/batch 35.76 | loss  4.50 | ppl    89.75\n",
            "| epoch  15 |  2600/ 2981 batches | lr 2.44 | ms/batch 35.84 | loss  4.52 | ppl    91.79\n",
            "| epoch  15 |  2800/ 2981 batches | lr 2.44 | ms/batch 35.77 | loss  4.47 | ppl    87.54\n",
            "| *** done epoch 15 | valid loss 5.4795 | ppl   239.72 | elapsed 109.94787812232971\n",
            "Adjusting learning rate of group 0 to 2.3165e+00.\n",
            "| epoch  16 |   200/ 2981 batches | lr 2.32 | ms/batch 36.07 | loss  4.53 | ppl    92.37\n",
            "| epoch  16 |   400/ 2981 batches | lr 2.32 | ms/batch 35.89 | loss  4.55 | ppl    94.68\n",
            "| epoch  16 |   600/ 2981 batches | lr 2.32 | ms/batch 35.83 | loss  4.38 | ppl    80.03\n",
            "| epoch  16 |   800/ 2981 batches | lr 2.32 | ms/batch 35.83 | loss  4.44 | ppl    84.49\n",
            "| epoch  16 |  1000/ 2981 batches | lr 2.32 | ms/batch 35.77 | loss  4.44 | ppl    85.03\n",
            "| epoch  16 |  1200/ 2981 batches | lr 2.32 | ms/batch 35.73 | loss  4.48 | ppl    88.02\n",
            "| epoch  16 |  1400/ 2981 batches | lr 2.32 | ms/batch 35.78 | loss  4.49 | ppl    89.02\n",
            "| epoch  16 |  1600/ 2981 batches | lr 2.32 | ms/batch 35.94 | loss  4.54 | ppl    93.69\n",
            "| epoch  16 |  1800/ 2981 batches | lr 2.32 | ms/batch 35.85 | loss  4.50 | ppl    90.24\n",
            "| epoch  16 |  2000/ 2981 batches | lr 2.32 | ms/batch 35.82 | loss  4.51 | ppl    91.25\n",
            "| epoch  16 |  2200/ 2981 batches | lr 2.32 | ms/batch 35.71 | loss  4.37 | ppl    79.38\n",
            "| epoch  16 |  2400/ 2981 batches | lr 2.32 | ms/batch 35.65 | loss  4.45 | ppl    85.65\n",
            "| epoch  16 |  2600/ 2981 batches | lr 2.32 | ms/batch 35.83 | loss  4.48 | ppl    87.98\n",
            "| epoch  16 |  2800/ 2981 batches | lr 2.32 | ms/batch 35.62 | loss  4.43 | ppl    83.77\n",
            "| *** done epoch 16 | valid loss 5.4731 | ppl   238.19 | elapsed 110.05091404914856\n",
            "Adjusting learning rate of group 0 to 2.2006e+00.\n",
            "| epoch  17 |   200/ 2981 batches | lr 2.20 | ms/batch 35.97 | loss  4.48 | ppl    88.64\n",
            "| epoch  17 |   400/ 2981 batches | lr 2.20 | ms/batch 35.95 | loss  4.51 | ppl    91.15\n",
            "| epoch  17 |   600/ 2981 batches | lr 2.20 | ms/batch 35.90 | loss  4.34 | ppl    77.00\n",
            "| epoch  17 |   800/ 2981 batches | lr 2.20 | ms/batch 35.85 | loss  4.40 | ppl    81.82\n",
            "| epoch  17 |  1000/ 2981 batches | lr 2.20 | ms/batch 35.73 | loss  4.40 | ppl    81.81\n",
            "| epoch  17 |  1200/ 2981 batches | lr 2.20 | ms/batch 35.83 | loss  4.44 | ppl    84.48\n",
            "| epoch  17 |  1400/ 2981 batches | lr 2.20 | ms/batch 35.83 | loss  4.44 | ppl    85.19\n",
            "| epoch  17 |  1600/ 2981 batches | lr 2.20 | ms/batch 35.98 | loss  4.50 | ppl    90.32\n",
            "| epoch  17 |  1800/ 2981 batches | lr 2.20 | ms/batch 35.80 | loss  4.46 | ppl    86.81\n",
            "| epoch  17 |  2000/ 2981 batches | lr 2.20 | ms/batch 35.76 | loss  4.48 | ppl    87.80\n",
            "| epoch  17 |  2200/ 2981 batches | lr 2.20 | ms/batch 35.88 | loss  4.34 | ppl    76.53\n",
            "| epoch  17 |  2400/ 2981 batches | lr 2.20 | ms/batch 35.70 | loss  4.42 | ppl    82.87\n",
            "| epoch  17 |  2600/ 2981 batches | lr 2.20 | ms/batch 35.76 | loss  4.44 | ppl    85.17\n",
            "| epoch  17 |  2800/ 2981 batches | lr 2.20 | ms/batch 35.85 | loss  4.39 | ppl    80.84\n",
            "| *** done epoch 17 | valid loss 5.5008 | ppl   244.89 | elapsed 110.16888952255249\n",
            "Adjusting learning rate of group 0 to 2.0906e+00.\n",
            "| epoch  18 |   200/ 2981 batches | lr 2.09 | ms/batch 35.97 | loss  4.45 | ppl    85.49\n",
            "| epoch  18 |   400/ 2981 batches | lr 2.09 | ms/batch 35.86 | loss  4.48 | ppl    88.31\n",
            "| epoch  18 |   600/ 2981 batches | lr 2.09 | ms/batch 35.74 | loss  4.31 | ppl    74.55\n",
            "| epoch  18 |   800/ 2981 batches | lr 2.09 | ms/batch 35.69 | loss  4.37 | ppl    79.19\n",
            "| epoch  18 |  1000/ 2981 batches | lr 2.09 | ms/batch 35.68 | loss  4.37 | ppl    79.18\n",
            "| epoch  18 |  1200/ 2981 batches | lr 2.09 | ms/batch 35.75 | loss  4.40 | ppl    81.66\n",
            "| epoch  18 |  1400/ 2981 batches | lr 2.09 | ms/batch 35.72 | loss  4.41 | ppl    82.24\n",
            "| epoch  18 |  1600/ 2981 batches | lr 2.09 | ms/batch 35.71 | loss  4.47 | ppl    86.97\n",
            "| epoch  18 |  1800/ 2981 batches | lr 2.09 | ms/batch 35.92 | loss  4.43 | ppl    84.33\n",
            "| epoch  18 |  2000/ 2981 batches | lr 2.09 | ms/batch 35.81 | loss  4.44 | ppl    84.44\n",
            "| epoch  18 |  2200/ 2981 batches | lr 2.09 | ms/batch 35.77 | loss  4.30 | ppl    73.96\n",
            "| epoch  18 |  2400/ 2981 batches | lr 2.09 | ms/batch 35.87 | loss  4.38 | ppl    79.79\n",
            "| epoch  18 |  2600/ 2981 batches | lr 2.09 | ms/batch 35.76 | loss  4.41 | ppl    81.94\n",
            "| epoch  18 |  2800/ 2981 batches | lr 2.09 | ms/batch 35.76 | loss  4.36 | ppl    78.13\n",
            "| *** done epoch 18 | valid loss 5.4897 | ppl   242.19 | elapsed 109.93761587142944\n",
            "Adjusting learning rate of group 0 to 1.9861e+00.\n",
            "| epoch  19 |   200/ 2981 batches | lr 1.99 | ms/batch 36.13 | loss  4.42 | ppl    82.83\n",
            "| epoch  19 |   400/ 2981 batches | lr 1.99 | ms/batch 35.82 | loss  4.44 | ppl    85.02\n",
            "| epoch  19 |   600/ 2981 batches | lr 1.99 | ms/batch 35.81 | loss  4.28 | ppl    72.15\n",
            "| epoch  19 |   800/ 2981 batches | lr 1.99 | ms/batch 35.71 | loss  4.34 | ppl    76.38\n",
            "| epoch  19 |  1000/ 2981 batches | lr 1.99 | ms/batch 35.68 | loss  4.34 | ppl    76.98\n",
            "| epoch  19 |  1200/ 2981 batches | lr 1.99 | ms/batch 35.83 | loss  4.37 | ppl    79.11\n",
            "| epoch  19 |  1400/ 2981 batches | lr 1.99 | ms/batch 35.67 | loss  4.38 | ppl    79.61\n",
            "| epoch  19 |  1600/ 2981 batches | lr 1.99 | ms/batch 35.76 | loss  4.43 | ppl    84.10\n",
            "| epoch  19 |  1800/ 2981 batches | lr 1.99 | ms/batch 35.86 | loss  4.40 | ppl    81.51\n",
            "| epoch  19 |  2000/ 2981 batches | lr 1.99 | ms/batch 35.67 | loss  4.40 | ppl    81.79\n",
            "| epoch  19 |  2200/ 2981 batches | lr 1.99 | ms/batch 35.75 | loss  4.27 | ppl    71.69\n",
            "| epoch  19 |  2400/ 2981 batches | lr 1.99 | ms/batch 35.83 | loss  4.35 | ppl    77.15\n",
            "| epoch  19 |  2600/ 2981 batches | lr 1.99 | ms/batch 35.71 | loss  4.37 | ppl    79.03\n",
            "| epoch  19 |  2800/ 2981 batches | lr 1.99 | ms/batch 35.70 | loss  4.32 | ppl    75.44\n",
            "| *** done epoch 19 | valid loss 5.5082 | ppl   246.70 | elapsed 109.94040060043335\n",
            "Adjusting learning rate of group 0 to 1.8868e+00.\n",
            "| epoch  20 |   200/ 2981 batches | lr 1.89 | ms/batch 35.95 | loss  4.39 | ppl    80.30\n",
            "| epoch  20 |   400/ 2981 batches | lr 1.89 | ms/batch 35.61 | loss  4.41 | ppl    82.19\n",
            "| epoch  20 |   600/ 2981 batches | lr 1.89 | ms/batch 35.68 | loss  4.25 | ppl    69.78\n",
            "| epoch  20 |   800/ 2981 batches | lr 1.89 | ms/batch 35.90 | loss  4.31 | ppl    74.17\n",
            "| epoch  20 |  1000/ 2981 batches | lr 1.89 | ms/batch 35.74 | loss  4.31 | ppl    74.64\n",
            "| epoch  20 |  1200/ 2981 batches | lr 1.89 | ms/batch 35.81 | loss  4.34 | ppl    76.57\n",
            "| epoch  20 |  1400/ 2981 batches | lr 1.89 | ms/batch 35.71 | loss  4.34 | ppl    76.96\n",
            "| epoch  20 |  1600/ 2981 batches | lr 1.89 | ms/batch 35.74 | loss  4.41 | ppl    81.94\n",
            "| epoch  20 |  1800/ 2981 batches | lr 1.89 | ms/batch 35.79 | loss  4.37 | ppl    79.04\n",
            "| epoch  20 |  2000/ 2981 batches | lr 1.89 | ms/batch 35.67 | loss  4.38 | ppl    79.78\n",
            "| epoch  20 |  2200/ 2981 batches | lr 1.89 | ms/batch 35.85 | loss  4.24 | ppl    69.32\n",
            "| epoch  20 |  2400/ 2981 batches | lr 1.89 | ms/batch 35.92 | loss  4.32 | ppl    75.10\n",
            "| epoch  20 |  2600/ 2981 batches | lr 1.89 | ms/batch 35.79 | loss  4.34 | ppl    76.57\n",
            "| epoch  20 |  2800/ 2981 batches | lr 1.89 | ms/batch 35.75 | loss  4.30 | ppl    73.38\n",
            "| *** done epoch 20 | valid loss 5.5075 | ppl   246.52 | elapsed 109.94283676147461\n",
            "Adjusting learning rate of group 0 to 1.7924e+00.\n",
            "| epoch  21 |   200/ 2981 batches | lr 1.79 | ms/batch 35.87 | loss  4.36 | ppl    77.87\n",
            "| epoch  21 |   400/ 2981 batches | lr 1.79 | ms/batch 35.68 | loss  4.38 | ppl    79.81\n",
            "| epoch  21 |   600/ 2981 batches | lr 1.79 | ms/batch 35.70 | loss  4.21 | ppl    67.67\n",
            "| epoch  21 |   800/ 2981 batches | lr 1.79 | ms/batch 35.80 | loss  4.27 | ppl    71.85\n",
            "| epoch  21 |  1000/ 2981 batches | lr 1.79 | ms/batch 35.80 | loss  4.29 | ppl    72.74\n",
            "| epoch  21 |  1200/ 2981 batches | lr 1.79 | ms/batch 35.69 | loss  4.31 | ppl    74.63\n",
            "| epoch  21 |  1400/ 2981 batches | lr 1.79 | ms/batch 35.73 | loss  4.32 | ppl    74.84\n",
            "| epoch  21 |  1600/ 2981 batches | lr 1.79 | ms/batch 35.90 | loss  4.37 | ppl    79.05\n",
            "| epoch  21 |  1800/ 2981 batches | lr 1.79 | ms/batch 35.82 | loss  4.34 | ppl    76.93\n",
            "| epoch  21 |  2000/ 2981 batches | lr 1.79 | ms/batch 35.81 | loss  4.35 | ppl    77.26\n",
            "| epoch  21 |  2200/ 2981 batches | lr 1.79 | ms/batch 35.84 | loss  4.21 | ppl    67.46\n",
            "| epoch  21 |  2400/ 2981 batches | lr 1.79 | ms/batch 35.76 | loss  4.29 | ppl    72.96\n",
            "| epoch  21 |  2600/ 2981 batches | lr 1.79 | ms/batch 35.76 | loss  4.31 | ppl    74.31\n",
            "| epoch  21 |  2800/ 2981 batches | lr 1.79 | ms/batch 35.63 | loss  4.27 | ppl    71.41\n",
            "| *** done epoch 21 | valid loss 5.5274 | ppl   251.49 | elapsed 109.90565133094788\n",
            "Adjusting learning rate of group 0 to 1.7028e+00.\n",
            "| epoch  22 |   200/ 2981 batches | lr 1.70 | ms/batch 35.88 | loss  4.33 | ppl    75.95\n",
            "| epoch  22 |   400/ 2981 batches | lr 1.70 | ms/batch 35.56 | loss  4.35 | ppl    77.80\n",
            "| epoch  22 |   600/ 2981 batches | lr 1.70 | ms/batch 35.57 | loss  4.19 | ppl    66.30\n",
            "| epoch  22 |   800/ 2981 batches | lr 1.70 | ms/batch 35.66 | loss  4.25 | ppl    70.31\n",
            "| epoch  22 |  1000/ 2981 batches | lr 1.70 | ms/batch 35.76 | loss  4.26 | ppl    70.91\n",
            "| epoch  22 |  1200/ 2981 batches | lr 1.70 | ms/batch 35.82 | loss  4.28 | ppl    72.55\n",
            "| epoch  22 |  1400/ 2981 batches | lr 1.70 | ms/batch 36.02 | loss  4.29 | ppl    73.07\n",
            "| epoch  22 |  1600/ 2981 batches | lr 1.70 | ms/batch 35.86 | loss  4.35 | ppl    77.29\n",
            "| epoch  22 |  1800/ 2981 batches | lr 1.70 | ms/batch 35.80 | loss  4.32 | ppl    75.09\n",
            "| epoch  22 |  2000/ 2981 batches | lr 1.70 | ms/batch 35.73 | loss  4.32 | ppl    75.30\n",
            "| epoch  22 |  2200/ 2981 batches | lr 1.70 | ms/batch 35.75 | loss  4.18 | ppl    65.62\n",
            "| epoch  22 |  2400/ 2981 batches | lr 1.70 | ms/batch 35.74 | loss  4.26 | ppl    70.52\n",
            "| epoch  22 |  2600/ 2981 batches | lr 1.70 | ms/batch 35.98 | loss  4.28 | ppl    72.35\n",
            "| epoch  22 |  2800/ 2981 batches | lr 1.70 | ms/batch 35.79 | loss  4.24 | ppl    69.49\n",
            "| *** done epoch 22 | valid loss 5.5344 | ppl   253.25 | elapsed 109.97848176956177\n",
            "Adjusting learning rate of group 0 to 1.6177e+00.\n",
            "| epoch  23 |   200/ 2981 batches | lr 1.62 | ms/batch 35.99 | loss  4.30 | ppl    73.85\n",
            "| epoch  23 |   400/ 2981 batches | lr 1.62 | ms/batch 35.87 | loss  4.33 | ppl    75.74\n",
            "| epoch  23 |   600/ 2981 batches | lr 1.62 | ms/batch 35.85 | loss  4.17 | ppl    64.68\n",
            "| epoch  23 |   800/ 2981 batches | lr 1.62 | ms/batch 35.84 | loss  4.23 | ppl    68.52\n",
            "| epoch  23 |  1000/ 2981 batches | lr 1.62 | ms/batch 35.81 | loss  4.24 | ppl    69.32\n",
            "| epoch  23 |  1200/ 2981 batches | lr 1.62 | ms/batch 35.86 | loss  4.26 | ppl    70.63\n",
            "| epoch  23 |  1400/ 2981 batches | lr 1.62 | ms/batch 35.93 | loss  4.26 | ppl    71.11\n",
            "| epoch  23 |  1600/ 2981 batches | lr 1.62 | ms/batch 35.89 | loss  4.32 | ppl    75.35\n",
            "| epoch  23 |  1800/ 2981 batches | lr 1.62 | ms/batch 35.77 | loss  4.29 | ppl    73.25\n",
            "| epoch  23 |  2000/ 2981 batches | lr 1.62 | ms/batch 35.73 | loss  4.29 | ppl    73.23\n",
            "| epoch  23 |  2200/ 2981 batches | lr 1.62 | ms/batch 35.89 | loss  4.16 | ppl    64.15\n",
            "| epoch  23 |  2400/ 2981 batches | lr 1.62 | ms/batch 35.87 | loss  4.23 | ppl    69.03\n",
            "| epoch  23 |  2600/ 2981 batches | lr 1.62 | ms/batch 35.92 | loss  4.26 | ppl    70.57\n",
            "| epoch  23 |  2800/ 2981 batches | lr 1.62 | ms/batch 36.01 | loss  4.21 | ppl    67.52\n",
            "| *** done epoch 23 | valid loss 5.5431 | ppl   255.47 | elapsed 110.30936670303345\n",
            "Adjusting learning rate of group 0 to 1.5368e+00.\n",
            "| epoch  24 |   200/ 2981 batches | lr 1.54 | ms/batch 36.35 | loss  4.28 | ppl    72.20\n",
            "| epoch  24 |   400/ 2981 batches | lr 1.54 | ms/batch 36.08 | loss  4.30 | ppl    73.72\n",
            "| epoch  24 |   600/ 2981 batches | lr 1.54 | ms/batch 36.07 | loss  4.14 | ppl    62.97\n",
            "| epoch  24 |   800/ 2981 batches | lr 1.54 | ms/batch 36.13 | loss  4.20 | ppl    66.78\n",
            "| epoch  24 |  1000/ 2981 batches | lr 1.54 | ms/batch 36.14 | loss  4.21 | ppl    67.62\n",
            "| epoch  24 |  1200/ 2981 batches | lr 1.54 | ms/batch 35.98 | loss  4.24 | ppl    69.16\n",
            "| epoch  24 |  1400/ 2981 batches | lr 1.54 | ms/batch 35.91 | loss  4.24 | ppl    69.16\n",
            "| epoch  24 |  1600/ 2981 batches | lr 1.54 | ms/batch 35.99 | loss  4.30 | ppl    73.56\n",
            "| epoch  24 |  1800/ 2981 batches | lr 1.54 | ms/batch 36.01 | loss  4.27 | ppl    71.45\n",
            "| epoch  24 |  2000/ 2981 batches | lr 1.54 | ms/batch 36.08 | loss  4.27 | ppl    71.62\n",
            "| epoch  24 |  2200/ 2981 batches | lr 1.54 | ms/batch 35.83 | loss  4.14 | ppl    62.52\n",
            "| epoch  24 |  2400/ 2981 batches | lr 1.54 | ms/batch 35.77 | loss  4.21 | ppl    67.26\n",
            "| epoch  24 |  2600/ 2981 batches | lr 1.54 | ms/batch 35.83 | loss  4.23 | ppl    68.61\n",
            "| epoch  24 |  2800/ 2981 batches | lr 1.54 | ms/batch 35.84 | loss  4.19 | ppl    65.96\n",
            "| *** done epoch 24 | valid loss 5.5393 | ppl   254.49 | elapsed 110.6039628982544\n",
            "Adjusting learning rate of group 0 to 1.4599e+00.\n",
            "| epoch  25 |   200/ 2981 batches | lr 1.46 | ms/batch 36.38 | loss  4.25 | ppl    70.46\n",
            "| epoch  25 |   400/ 2981 batches | lr 1.46 | ms/batch 36.09 | loss  4.27 | ppl    71.86\n",
            "| epoch  25 |   600/ 2981 batches | lr 1.46 | ms/batch 36.09 | loss  4.12 | ppl    61.60\n",
            "| epoch  25 |   800/ 2981 batches | lr 1.46 | ms/batch 35.99 | loss  4.18 | ppl    65.28\n",
            "| epoch  25 |  1000/ 2981 batches | lr 1.46 | ms/batch 36.03 | loss  4.19 | ppl    66.33\n",
            "| epoch  25 |  1200/ 2981 batches | lr 1.46 | ms/batch 36.02 | loss  4.21 | ppl    67.58\n",
            "| epoch  25 |  1400/ 2981 batches | lr 1.46 | ms/batch 35.97 | loss  4.22 | ppl    67.78\n",
            "| epoch  25 |  1600/ 2981 batches | lr 1.46 | ms/batch 36.06 | loss  4.27 | ppl    71.67\n",
            "| epoch  25 |  1800/ 2981 batches | lr 1.46 | ms/batch 36.04 | loss  4.25 | ppl    70.38\n",
            "| epoch  25 |  2000/ 2981 batches | lr 1.46 | ms/batch 36.03 | loss  4.25 | ppl    70.10\n",
            "| epoch  25 |  2200/ 2981 batches | lr 1.46 | ms/batch 36.09 | loss  4.11 | ppl    61.13\n",
            "| epoch  25 |  2400/ 2981 batches | lr 1.46 | ms/batch 36.22 | loss  4.18 | ppl    65.33\n",
            "| epoch  25 |  2600/ 2981 batches | lr 1.46 | ms/batch 36.27 | loss  4.21 | ppl    67.34\n",
            "| epoch  25 |  2800/ 2981 batches | lr 1.46 | ms/batch 35.97 | loss  4.17 | ppl    64.53\n",
            "| *** done epoch 25 | valid loss 5.5453 | ppl   256.03 | elapsed 110.8186469078064\n",
            "Adjusting learning rate of group 0 to 1.3869e+00.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test set evaluation\n",
        "\n",
        "_, _, best_model = load_checkpoint_model(min_loss_epoch)\n",
        "\n",
        "test_loss = evaluate(best_model, test_data)\n",
        "test_ppl = np.exp(test_loss)\n",
        "print(f\"The test loss is {test_loss}\")\n",
        "print(f\"The test perplexity is {test_ppl}\")\n"
      ],
      "metadata": {
        "id": "gSBBNAwJ0lG3",
        "outputId": "cd9c5bf5-a5eb-4a4e-de85-92de38429514",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The test loss is 5.307821884135129\n",
            "The test perplexity is 201.9099657909663\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(40, 40))\n",
        "_, axes = plt.subplots(1, 2)\n",
        "\n",
        "x = range(1, hyper_params['EPOCHS'] + 1)\n",
        "\n",
        "axes[0].set_title(\"Validation losses per epoch\")\n",
        "axes[0].set_xlabel(\"epochs\")\n",
        "axes[0].plot(x, valid_losses)\n",
        "\n",
        "axes[1].set_title(\"perplexity per epoch\")\n",
        "axes[1].set_xlabel(\"epochs\")\n",
        "axes[1].plot(x, ppls)\n"
      ],
      "metadata": {
        "id": "QGsYKkoj14Ld",
        "outputId": "6a08c930-5303-473b-bc1e-dfa5a716fe3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fcf3123c850>]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2880x2880 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvAMKFzDpt6w"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/color/48/000000/code.png\" style=\"height:50px;display:inline\"> Task 5  - Generate Sentences\n",
        "---\n",
        "Use the following function to generate 3 sentences of length 20, and print them. Do they make sense? (you can compare generated sentences over epochs, to see if some logic is gained during training)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "1CsbI5Mwpt6x"
      },
      "outputs": [],
      "source": [
        "def generate(model, vocab, nwords=100, temp=1.0):\n",
        "    model.eval()\n",
        "    ntokens = len(vocab.stoi)\n",
        "    model_input = torch.randint(ntokens, (1, 1), dtype=torch.long).to(device)\n",
        "    words = []\n",
        "    with torch.no_grad():\n",
        "        for i in range(nwords):\n",
        "            output = model(model_input, None)\n",
        "            word_weights = output[-1].squeeze().div(temp).exp().cpu()\n",
        "            word_idx = torch.multinomial(word_weights, 1)[0]\n",
        "            word_tensor = torch.Tensor([[word_idx]]).long().to(device)\n",
        "            model_input = torch.cat([model_input, word_tensor], 0)\n",
        "            word = vocab.itos[word_idx]\n",
        "            words.append(word)\n",
        "    return words"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <img src=\"https://img.icons8.com/fluency/48/000000/exclamation-mark.png\" style=\"height:50px;display:inline\">  Task 5 Code and Answers  - Generate Sentences\n",
        "---"
      ],
      "metadata": {
        "id": "8h_sP5aO_k_z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJ6mLrZkpt6y",
        "outputId": "ca859ec5-b598-4d7a-a7ef-83628f2f3297"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "load checkpoint in training of epoch 1 and generate 3 sentences:\n",
            "stars are name in <unk> of the practices in the national evolution of the key . the initial lucrative patronage officials ) can be these night trachodon five befriended the facial feather <unk> such 1145 are has been used by class areas led by an interest when the future airborne by the choice dragon . <eos> <unk> philippines in this surface plumes and hope poor within some brethren of local areas of japan ( <unk> in habitat and armed , it , 2022 <unk> studies and sounded observed until sort of an average words of a vargas that pedestrian hot\n",
            "done to enter and an estimated at its eater to cross was named on orozco still associated with the adult birds for another no evolves while either three years of the major impact on robby for <unk> 767 men have been <unk> freeman , along with the first three <unk> , such as two times waterproofing of some characters conform its development in the kpa ' s design or land sharing , and piano . meanwhile and those of the prestigious ) between all changes and inhabits ( covering a large @-@ evidence of the forward in senator michael henry\n",
            "was placed in seconds to fencing , 373 from deadline or leaf , his death given by september 2014 . hamels ' s support for chicago church , however , saint , particularly after taff caught , it contained most distinguished and mountain for attacking <unk> a modern times and biography , a sisters did not launch actions , when india flower understandable and personal opera 2009 repeatedly , he villaret . 76ers , virginia tech , a young clandestine all . he signed for the song is a futile mountains of statue upon his return to ireland increased one\n",
            "\n",
            "load checkpoint in training of epoch 3 and generate 3 sentences:\n",
            "to about 0 @ . @ 0 @ . @ . @ . @ . although horsepower ) , a 1 in ( 0 @ . @ 2 in ) . @ . @ 06 @ , @ . @ 0 @ 8 @ 0 @ 9 of 47 miles ( 0 @ 25 mm ) , a fourth @ . @ 5 @ 110 nathan , @ 0 in ) . @ . @ . in ( 0 in ( 2 / ( 0 @ . @ 74 in ) near the soldier , being fantastic testing , more\n",
            ", and receiving a salary 305 – 12 win away touchdown , virginia tech responded to 40 in earth and third quarter . thirty @-@ yard pass five plays during the first kicked 3 games spent in 2005 – 2 % . <eos> <eos> = <eos> = = = = = = = = = = = = = <eos> virginia tech , while he briefly , and a 30 in 81 plays lost 40 independent hockey / 33 – 0 @ . in 2010 season . <eos> <eos> <eos> <eos> <eos> <eos> <eos> <eos> on late on the first\n",
            "and his way his work , working together , which takes into dr . dwight , serpents . bernissartensis , living as they had been elected private shock . most notable opportunities from their fourth in dna friend , head , and @-@ researched dials barker runs . he had been found that he completed a salary to him by two years as he argued that caused by graph assign when he participated , number of the throne . <eos> minnesota as saying the eighteenth century . in the death and two ecological aspects of cassini <eos> = = =\n",
            "\n",
            "load checkpoint in training of epoch 6 and generate 3 sentences:\n",
            "2015 . the advancement of 326 in ulster , all kinds of information about written in defied tests were affixed to deal as of <unk> reviewed an uss o ' malley ' malley as certainty . he moved to begin a pro vingtième hide seven years old kingdom and frank mosley had been uncle oswald , it for 1902 production strategies and received a study isaiah <unk> offseason , the <unk> . henry james matt adams ' malley <unk> announced in his keen for cheyenne died possible to chris dash , failed to harm . <eos> in a younger wild\n",
            "state began the fourth as maryland the alabama batted soldiers record since the sec athletic association of alabama the first down failed to punt was 88 mvp in 1910 . <eos> = = = <eos> <eos> <eos> <eos> <eos> = visual effects = = <eos> virginia tech returned 1 @-@ yard return to win a touchdown reception = = <eos> <eos> rugby casey married = = <eos> <eos> a rugby ' s @-@ season with fellow vida , where the first season which surrounding the old and a touchdown kickoff . the second quarter <eos> <eos> <eos> <eos> <eos> tufaro\n",
            ", the tablets has both 1150 , has been published on their successful conception . <eos> <eos> = <eos> in japan , but felt that hornung wanted to for beating summer when a mass and published a man gave it , mulei of jules verne ' s 2010 . in 1818 , walpole ' s first he were examination was $ 72 ft child ' s chronicle ' s ten years from her previous years , unlike humans and a original text to hearted and weighs 25 millimetres ( 1995 – 0 @ . @ , after he turned to\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Your code Here\n",
        "\"\"\"\n",
        "def print_sentence(words):\n",
        "    sentence = \" \".join([t for _,t in enumerate(words)])\n",
        "    print(f\"{sentence}\")\n",
        "\n",
        "for j in [1, 3, 6]:\n",
        "    print(f\"\\nload checkpoint in training of epoch {j} and generate 3 sentences:\")\n",
        "    _, _, loaded_model = load_checkpoint_model(j)\n",
        "    for i in range(3):\n",
        "        words = generate(loaded_model, vocab)\n",
        "        print_sentence(words)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKfBYPQwpt6z"
      },
      "source": [
        "## <img src=\"https://img.icons8.com/dusk/64/000000/prize.png\" style=\"height:50px;display:inline\"> Credits\n",
        "---\n",
        "* Icons made by <a href=\"https://www.flaticon.com/authors/becris\" title=\"Becris\">Becris</a> from <a href=\"https://www.flaticon.com/\" title=\"Flaticon\">www.flaticon.com</a>\n",
        "* Icons from <a href=\"https://icons8.com/\">Icons8.com</a> - https://icons8.com\n",
        "* Datasets from <a href=\"https://www.kaggle.com/\">Kaggle</a> - https://www.kaggle.com/"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "colab": {
      "name": "ee046211_hw3_034462796_204034953.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}